import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io
import matplotlib.pyplot as plt
from pathlib import Path

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(
    page_title="Ø³Ù„Ø³Ù„Ø© Ù…Ø­Ø§Ø¶Ø±Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±",
    page_icon="ğŸ–¼ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS Ù…Ø®ØµØµ
st.markdown("""
<style>
    .main-header {
        text-align: center;
        color: #2E4057;
        font-size: 2.5rem;
        font-weight: bold;
        margin-bottom: 1rem;
    }
    .lecture-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        color: white;
        text-align: center;
    }
    .theory-box {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #4CAF50;
        margin: 1rem 0;
    }
    .sidebar .sidebar-content {
        background: linear-gradient(180deg, #667eea 0%, #764ba2 100%);
    }
</style>
""", unsafe_allow_html=True)

def main():
    # Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    st.markdown('<h1 class="main-header">ğŸ–¼ï¸ Ø³Ù„Ø³Ù„Ø© Ù…Ø­Ø§Ø¶Ø±Ø§Øª ØªÙØ§Ø¹Ù„ÙŠØ© ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±</h1>', unsafe_allow_html=True)
    
    # Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ù„Ù„ØªÙ†Ù‚Ù„
    st.sidebar.title("ğŸ“š Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø§Øª")
    
    lectures = {
        "Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©": "home",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 1: Ù…Ø¯Ø®Ù„ ÙˆÙ…Ø¹Ù…Ø§Ø±ÙŠØ© Ø§Ù„ØµÙˆØ± Ø§Ù„Ø±Ù‚Ù…ÙŠØ©": "lecture1",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 2: Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù†": "lecture2", 
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 3: Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙƒØ³Ù„": "lecture3",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 4: Ø§Ù„ÙÙ„Ø§ØªØ± ÙˆØ§Ù„Ø§Ù„ØªÙØ§Ù": "lecture4",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 5: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡": "lecture5",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 6: ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù": "lecture6",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 7: Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©": "lecture7",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 8: Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ©": "lecture8",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 9: Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ø®ØªØ§Ù…ÙŠ": "lecture9"
    }
    
    selected_lecture = st.sidebar.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø©:", list(lectures.keys()))
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©
    if lectures[selected_lecture] == "home":
        show_home_page()
    elif lectures[selected_lecture] == "lecture1":
        show_lecture1()
    elif lectures[selected_lecture] == "lecture2":
        show_lecture2()
    elif lectures[selected_lecture] == "lecture3":
        show_lecture3()
    elif lectures[selected_lecture] == "lecture4":
        show_lecture4()
    elif lectures[selected_lecture] == "lecture5":
        show_lecture5()
    elif lectures[selected_lecture] == "lecture6":
        show_lecture6()
    elif lectures[selected_lecture] == "lecture7":
        show_lecture7()
    elif lectures[selected_lecture] == "lecture8":
        show_lecture8()
    elif lectures[selected_lecture] == "lecture9":
        show_lecture9()

def show_home_page():
    """Ø¹Ø±Ø¶ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    st.markdown("""
    ## ğŸ¯ Ø£Ù‡Ø¯Ø§Ù Ø§Ù„Ø³Ù„Ø³Ù„Ø©
    
    ØªÙ‡Ø¯Ù Ù‡Ø°Ù‡ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ© Ø¥Ù„Ù‰ ØªØ¹Ù„ÙŠÙ… Ø£Ø³Ø§Ø³ÙŠØ§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ù…Ù† Ø®Ù„Ø§Ù„:
    
    - **Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ù†Ø¸Ø±ÙŠ Ø§Ù„Ù…Ø¨Ø³Ø·** Ù„ÙƒÙ„ Ù…ÙÙ‡ÙˆÙ…
    - **Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ** Ø¨Ø¯ÙˆÙ† ÙƒØªØ§Ø¨Ø© ÙƒÙˆØ¯
    - **Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©** Ø¨ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© ÙˆØ§Ù„Ù†ØªÙŠØ¬Ø©
    - **Ø§Ù„ØªØ­ÙƒÙ… Ø§Ù„ÙƒØ§Ù…Ù„** ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    
    ## ğŸ“‹ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø³Ù„Ø³Ù„Ø©
    """)
    
    # Ø¹Ø±Ø¶ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø§Øª
    lecture_descriptions = [
        ("Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 1", "Ù…Ø¯Ø®Ù„ ÙˆÙ…Ø¹Ù…Ø§Ø±ÙŠØ© Ø§Ù„ØµÙˆØ± Ø§Ù„Ø±Ù‚Ù…ÙŠØ©", "ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙƒØ³Ù„ ÙˆØ§Ù„Ø£Ø¨Ø¹Ø§Ø¯ ÙˆØ§Ù„Ù‚Ù†ÙˆØ§Øª"),
        ("Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 2", "Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù†", "RGB, HSV, Gray ÙˆØªØ­ÙˆÙŠÙ„ Ø¨ÙŠÙ†Ù‡Ø§"),
        ("Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 3", "Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙƒØ³Ù„", "Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ† ÙˆØ§Ù„Ø¹ØªØ¨Ø©"),
        ("Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 4", "Ø§Ù„ÙÙ„Ø§ØªØ± ÙˆØ§Ù„Ø§Ù„ØªÙØ§Ù", "Blur, Sharpen, Edge Detection"),
        ("Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 5", "Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡", "Median, Bilateral Filtering"),
        ("Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 6", "ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù", "Sobel, Laplacian, Canny"),
        ("Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 7", "Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©", "Erosion, Dilation, Opening, Closing"),
        ("Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 8", "Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ©", "Rotation, Scaling, Translation"),
        ("Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 9", "Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ø®ØªØ§Ù…ÙŠ", "ØªØ·Ø¨ÙŠÙ‚ Ø´Ø§Ù…Ù„ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª")
    ]
    
    for i, (title, subtitle, description) in enumerate(lecture_descriptions, 1):
        with st.expander(f"{title}: {subtitle}"):
            st.write(f"ğŸ“ {description}")
    
    st.markdown("""
    ---
    ## ğŸš€ Ø§Ø¨Ø¯Ø£ Ø§Ù„Ø¢Ù†
    
    Ø§Ø®ØªØ± Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ù„Ø¨Ø¯Ø¡ Ø±Ø­Ù„ØªÙƒ ÙÙŠ ØªØ¹Ù„Ù… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±!
    """)

# Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø§Øª (Ø³ÙŠØªÙ… ØªØ·ÙˆÙŠØ±Ù‡Ø§ ÙÙŠ Ø§Ù„Ù…Ø±Ø§Ø­Ù„ Ø§Ù„ØªØ§Ù„ÙŠØ©)
def show_lecture1():
    st.title("Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 1: Ù…Ø¯Ø®Ù„ ÙˆÙ…Ø¹Ù…Ø§Ø±ÙŠØ© Ø§Ù„ØµÙˆØ± Ø§Ù„Ø±Ù‚Ù…ÙŠØ©")
    
    # Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù†Ø¸Ø±ÙŠ
    st.markdown("""
    <div class="theory-box">
    <h3>ğŸ“ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù†Ø¸Ø±ÙŠ</h3>
    <p><strong>Ù…Ø§ Ù‡ÙŠ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©ØŸ</strong></p>
    <p>Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ù‡ÙŠ Ù…ØµÙÙˆÙØ© Ø«Ù†Ø§Ø¦ÙŠØ© Ø£Ùˆ Ø«Ù„Ø§Ø«ÙŠØ© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù…Ù† Ø§Ù„Ø¨ÙƒØ³Ù„Ø§Øª (Pixels). ÙƒÙ„ Ø¨ÙƒØ³Ù„ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚ÙŠÙ…Ø© Ø±Ù‚Ù…ÙŠØ© ØªÙ…Ø«Ù„ Ø´Ø¯Ø© Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø© Ø£Ùˆ Ø§Ù„Ù„ÙˆÙ†.</p>
    <p><strong>Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:</strong></p>
    <ul>
    <li><strong>Ø§Ù„Ø¨ÙƒØ³Ù„ (Pixel):</strong> Ø£ØµØºØ± ÙˆØ­Ø¯Ø© ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©</li>
    <li><strong>Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯:</strong> Ø§Ù„Ø¹Ø±Ø¶ Ã— Ø§Ù„Ø§Ø±ØªÙØ§Ø¹ Ã— Ø§Ù„Ù‚Ù†ÙˆØ§Øª</li>
    <li><strong>Ø§Ù„Ø¹Ù…Ù‚ Ø§Ù„Ù„ÙˆÙ†ÙŠ:</strong> Ø¹Ø¯Ø¯ Ø§Ù„Ø¨ØªØ§Øª Ù„ÙƒÙ„ Ø¨ÙƒØ³Ù„ (8-bit, 16-bit, etc.)</li>
    <li><strong>Ø§Ù„Ù‚Ù†ÙˆØ§Øª (Channels):</strong> R, G, B Ù„Ù„Ø£Ù„ÙˆØ§Ù† Ø£Ùˆ Ù‚Ù†Ø§Ø© ÙˆØ§Ø­Ø¯Ø© Ù„Ù„Ø±Ù…Ø§Ø¯ÙŠ</li>
    </ul>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠ
    st.markdown("## ğŸ”¬ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠ")
    
    # Ø®ÙŠØ§Ø±Ø§Øª ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ğŸ“ ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø©")
        uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø©", type=['png', 'jpg', 'jpeg'])
    
    with col2:
        st.subheader("ğŸ–¼ï¸ Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… ØµÙˆØ±Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ©")
        use_sample = st.button("Ø§Ø³ØªØ®Ø¯Ù… ØµÙˆØ±Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ©")
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
    if uploaded_file is not None:
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©
        image = load_image(uploaded_file)
        process_image_info(image, "Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©")
        
    elif use_sample:
        # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ©
        sample_image = create_sample_image()
        process_image_info(sample_image, "Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠØ©")

def process_image_info(image, title):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØµÙˆØ±Ø©"""
    st.markdown(f"### ğŸ“Š ØªØ­Ù„ÙŠÙ„ {title}")
    
    # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©")
        st.image(image, caption=title, use_column_width=True)
    
    with col2:
        st.subheader("Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØµÙˆØ±Ø©")
        
        # Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯
        height, width = image.shape[:2]
        channels = image.shape[2] if len(image.shape) == 3 else 1
        
        st.metric("Ø§Ù„Ø§Ø±ØªÙØ§Ø¹ (Height)", f"{height} Ø¨ÙƒØ³Ù„")
        st.metric("Ø§Ù„Ø¹Ø±Ø¶ (Width)", f"{width} Ø¨ÙƒØ³Ù„")
        st.metric("Ø§Ù„Ù‚Ù†ÙˆØ§Øª (Channels)", channels)
        st.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¨ÙƒØ³Ù„Ø§Øª", f"{height * width:,}")
        
        # Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        st.write(f"**Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:** {image.dtype}")
        st.write(f"**Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ù‚ÙŠÙ…:** {image.min()}")
        st.write(f"**Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ù‚ÙŠÙ…:** {image.max()}")
        st.write(f"**Ù…ØªÙˆØ³Ø· Ø§Ù„Ù‚ÙŠÙ…:** {image.mean():.2f}")
    
    # Ø¹Ø±Ø¶ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù‚Ù†ÙˆØ§Øª
    if len(image.shape) == 3 and image.shape[2] == 3:
        st.markdown("### ğŸ¨ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ù†ÙˆØ§Øª")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.subheader("Ø§Ù„Ù‚Ù†Ø§Ø© Ø§Ù„Ø­Ù…Ø±Ø§Ø¡ (R)")
            red_channel = image[:, :, 0]
            st.image(red_channel, caption="Red Channel", use_column_width=True, clamp=True)
            st.write(f"Ù…ØªÙˆØ³Ø·: {red_channel.mean():.2f}")
        
        with col2:
            st.subheader("Ø§Ù„Ù‚Ù†Ø§Ø© Ø§Ù„Ø®Ø¶Ø±Ø§Ø¡ (G)")
            green_channel = image[:, :, 1]
            st.image(green_channel, caption="Green Channel", use_column_width=True, clamp=True)
            st.write(f"Ù…ØªÙˆØ³Ø·: {green_channel.mean():.2f}")
        
        with col3:
            st.subheader("Ø§Ù„Ù‚Ù†Ø§Ø© Ø§Ù„Ø²Ø±Ù‚Ø§Ø¡ (B)")
            blue_channel = image[:, :, 2]
            st.image(blue_channel, caption="Blue Channel", use_column_width=True, clamp=True)
            st.write(f"Ù…ØªÙˆØ³Ø·: {blue_channel.mean():.2f}")
    
    # Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„ØªÙˆØ²ÙŠØ¹
    st.markdown("### ğŸ“ˆ ØªÙˆØ²ÙŠØ¹ Ø´Ø¯Ø© Ø§Ù„Ø¨ÙƒØ³Ù„Ø§Øª")
    
    if len(image.shape) == 3:
        # Ù„Ù„ØµÙˆØ± Ø§Ù„Ù…Ù„ÙˆÙ†Ø©
        fig, ax = plt.subplots(figsize=(10, 4))
        colors = ['red', 'green', 'blue']
        labels = ['Ø£Ø­Ù…Ø±', 'Ø£Ø®Ø¶Ø±', 'Ø£Ø²Ø±Ù‚']
        
        for i, (color, label) in enumerate(zip(colors, labels)):
            hist, bins = np.histogram(image[:, :, i].flatten(), bins=50, range=(0, 255))
            ax.plot(bins[:-1], hist, color=color, label=label, alpha=0.7)
        
        ax.set_xlabel('Ø´Ø¯Ø© Ø§Ù„Ø¨ÙƒØ³Ù„')
        ax.set_ylabel('Ø§Ù„ØªÙƒØ±Ø§Ø±')
        ax.set_title('ØªÙˆØ²ÙŠØ¹ Ø´Ø¯Ø© Ø§Ù„Ø¨ÙƒØ³Ù„Ø§Øª Ù„ÙƒÙ„ Ù‚Ù†Ø§Ø©')
        ax.legend()
        st.pyplot(fig)
    else:
        # Ù„Ù„ØµÙˆØ± Ø§Ù„Ø±Ù…Ø§Ø¯ÙŠØ©
        fig, ax = plt.subplots(figsize=(10, 4))
        hist, bins = np.histogram(image.flatten(), bins=50, range=(0, 255))
        ax.plot(bins[:-1], hist, color='gray')
        ax.set_xlabel('Ø´Ø¯Ø© Ø§Ù„Ø¨ÙƒØ³Ù„')
        ax.set_ylabel('Ø§Ù„ØªÙƒØ±Ø§Ø±')
        ax.set_title('ØªÙˆØ²ÙŠØ¹ Ø´Ø¯Ø© Ø§Ù„Ø¨ÙƒØ³Ù„Ø§Øª')
        st.pyplot(fig)

def create_sample_image():
    """Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
    # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ù…Ù„ÙˆÙ†Ø© Ø¨Ø³ÙŠØ·Ø©
    height, width = 200, 300
    image = np.zeros((height, width, 3), dtype=np.uint8)
    
    # Ø¥Ø¶Ø§ÙØ© Ø£Ø´ÙƒØ§Ù„ Ù…Ù„ÙˆÙ†Ø©
    # Ù…Ø±Ø¨Ø¹ Ø£Ø­Ù…Ø±
    image[50:100, 50:100] = [255, 0, 0]
    # Ù…Ø±Ø¨Ø¹ Ø£Ø®Ø¶Ø±
    image[50:100, 150:200] = [0, 255, 0]
    # Ù…Ø±Ø¨Ø¹ Ø£Ø²Ø±Ù‚
    image[120:170, 100:150] = [0, 0, 255]
    
    return image

def show_lecture2():
    st.title("Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 2: Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù†")
    
    # Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù†Ø¸Ø±ÙŠ
    st.markdown("""
    <div class="theory-box">
    <h3>ğŸ“ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù†Ø¸Ø±ÙŠ</h3>
    <p><strong>Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù† (Color Spaces):</strong></p>
    <ul>
    <li><strong>RGB:</strong> Ø£Ø­Ù…Ø±ØŒ Ø£Ø®Ø¶Ø±ØŒ Ø£Ø²Ø±Ù‚ - Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹ ÙÙŠ Ø§Ù„Ø´Ø§Ø´Ø§Øª</li>
    <li><strong>BGR:</strong> Ø£Ø²Ø±Ù‚ØŒ Ø£Ø®Ø¶Ø±ØŒ Ø£Ø­Ù…Ø± - ÙŠØ³ØªØ®Ø¯Ù…Ù‡ OpenCV Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹</li>
    <li><strong>Gray:</strong> Ø§Ù„Ø±Ù…Ø§Ø¯ÙŠ - Ù‚Ù†Ø§Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·ØŒ ÙŠÙˆÙØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆÙŠØ³Ø±Ø¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©</li>
    <li><strong>HSV:</strong> ØªØ¯Ø±Ø¬ØŒ ØªØ´Ø¨Ø¹ØŒ Ù‚ÙŠÙ…Ø© - Ù…ÙÙŠØ¯ Ù„ÙƒØ´Ù Ø§Ù„Ø£Ù„ÙˆØ§Ù† ÙˆØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ø­Ø§Ø³ÙˆØ¨ÙŠØ©</li>
    </ul>
    <p><strong>Ù…ØªÙ‰ Ù†Ø³ØªØ®Ø¯Ù… ÙƒÙ„ Ù†Ø¸Ø§Ù…ØŸ</strong> RGB Ù„Ù„Ø¹Ø±Ø¶ØŒ Gray Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø©ØŒ HSV Ù„ÙƒØ´Ù Ø§Ù„Ø£Ù„ÙˆØ§Ù†</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠ
    st.markdown("## ğŸ”¬ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠ")
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
    col1, col2 = st.columns([1, 1])
    
    with col1:
        uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø©", type=['png', 'jpg', 'jpeg'], key="lecture2")
    
    with col2:
        use_sample = st.button("Ø§Ø³ØªØ®Ø¯Ù… ØµÙˆØ±Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ©", key="sample2")
    
    if uploaded_file is not None:
        image = load_image(uploaded_file)
        show_color_spaces(image)
    elif use_sample:
        sample_image = create_colorful_sample_image()
        show_color_spaces(sample_image)

def show_color_spaces(image):
    """Ø¹Ø±Ø¶ ØªØ­ÙˆÙŠÙ„Ø§Øª Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù†"""
    st.markdown("### ğŸ¨ ØªØ­ÙˆÙŠÙ„ Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù†")
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ OpenCV
    if len(image.shape) == 3:
        # ØªØ­ÙˆÙŠÙ„ Ù…Ù† RGB Ø¥Ù„Ù‰ BGR Ù„Ù„Ø¹Ù…Ù„ Ù…Ø¹ OpenCV
        bgr_image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        
        # Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
        gray_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)
        hsv_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2HSV)
        
        # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© (RGB)")
            st.image(image, caption="RGB Image", use_column_width=True)
        
        with col2:
            st.subheader("Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø±Ù…Ø§Ø¯ÙŠØ© (Gray)")
            st.image(gray_image, caption="Grayscale Image", use_column_width=True, clamp=True)
        
        col3, col4 = st.columns(2)
        
        with col3:
            st.subheader("Ù†Ø¸Ø§Ù… HSV")
            # ØªØ­ÙˆÙŠÙ„ HSV Ù„Ù„Ø¹Ø±Ø¶
            hsv_display = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)
            st.image(hsv_display, caption="HSV Image", use_column_width=True)
        
        with col4:
            st.subheader("Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ­ÙˆÙŠÙ„")
            st.write("**RGB â†’ Gray:** Ù…ØªÙˆØ³Ø· Ù…Ø±Ø¬Ø­ Ù„Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ø«Ù„Ø§Ø«")
            st.write("**RGB â†’ HSV:** ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØªØ¯Ø±Ø¬ ÙˆØªØ´Ø¨Ø¹ ÙˆÙ‚ÙŠÙ…Ø©")
            st.write(f"**Ø­Ø¬Ù… RGB:** {image.shape}")
            st.write(f"**Ø­Ø¬Ù… Gray:** {gray_image.shape}")
            st.write(f"**Ø­Ø¬Ù… HSV:** {hsv_image.shape}")
    
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù‚Ù†ÙˆØ§Øª
    if len(image.shape) == 3 and image.shape[2] == 3:
        st.markdown("### ğŸ” ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù‚Ù†ÙˆØ§Øª")
        
        tab1, tab2 = st.tabs(["Ù‚Ù†ÙˆØ§Øª RGB", "Ù‚Ù†ÙˆØ§Øª HSV"])
        
        with tab1:
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.subheader("Ø§Ù„Ù‚Ù†Ø§Ø© Ø§Ù„Ø­Ù…Ø±Ø§Ø¡")
                red_channel = image[:, :, 0]
                st.image(red_channel, caption="Red Channel", use_column_width=True, clamp=True)
                st.write(f"Ø§Ù„Ù…ØªÙˆØ³Ø·: {red_channel.mean():.1f}")
                st.write(f"Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ: {red_channel.std():.1f}")
            
            with col2:
                st.subheader("Ø§Ù„Ù‚Ù†Ø§Ø© Ø§Ù„Ø®Ø¶Ø±Ø§Ø¡")
                green_channel = image[:, :, 1]
                st.image(green_channel, caption="Green Channel", use_column_width=True, clamp=True)
                st.write(f"Ø§Ù„Ù…ØªÙˆØ³Ø·: {green_channel.mean():.1f}")
                st.write(f"Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ: {green_channel.std():.1f}")
            
            with col3:
                st.subheader("Ø§Ù„Ù‚Ù†Ø§Ø© Ø§Ù„Ø²Ø±Ù‚Ø§Ø¡")
                blue_channel = image[:, :, 2]
                st.image(blue_channel, caption="Blue Channel", use_column_width=True, clamp=True)
                st.write(f"Ø§Ù„Ù…ØªÙˆØ³Ø·: {blue_channel.mean():.1f}")
                st.write(f"Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ: {blue_channel.std():.1f}")
        
        with tab2:
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ HSV Ù„ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù‚Ù†ÙˆØ§Øª
            bgr_image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            hsv_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2HSV)
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.subheader("Ø§Ù„ØªØ¯Ø±Ø¬ (Hue)")
                hue_channel = hsv_image[:, :, 0]
                st.image(hue_channel, caption="Hue Channel", use_column_width=True, clamp=True)
                st.write(f"Ø§Ù„Ù…ØªÙˆØ³Ø·: {hue_channel.mean():.1f}")
            
            with col2:
                st.subheader("Ø§Ù„ØªØ´Ø¨Ø¹ (Saturation)")
                sat_channel = hsv_image[:, :, 1]
                st.image(sat_channel, caption="Saturation Channel", use_column_width=True, clamp=True)
                st.write(f"Ø§Ù„Ù…ØªÙˆØ³Ø·: {sat_channel.mean():.1f}")
            
            with col3:
                st.subheader("Ø§Ù„Ù‚ÙŠÙ…Ø© (Value)")
                val_channel = hsv_image[:, :, 2]
                st.image(val_channel, caption="Value Channel", use_column_width=True, clamp=True)
                st.write(f"Ø§Ù„Ù…ØªÙˆØ³Ø·: {val_channel.mean():.1f}")

def create_colorful_sample_image():
    """Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ© Ù…Ù„ÙˆÙ†Ø©"""
    height, width = 200, 300
    image = np.zeros((height, width, 3), dtype=np.uint8)
    
    # Ø¥Ù†Ø´Ø§Ø¡ ØªØ¯Ø±Ø¬Ø§Øª Ù…Ù„ÙˆÙ†Ø©
    for i in range(height):
        for j in range(width):
            # ØªØ¯Ø±Ø¬ Ù‚ÙˆØ³ Ù‚Ø²Ø­
            hue = int((j / width) * 180)
            saturation = 255
            value = 255 - int((i / height) * 100)
            
            # ØªØ­ÙˆÙŠÙ„ HSV Ø¥Ù„Ù‰ RGB
            hsv_pixel = np.uint8([[[hue, saturation, value]]])
            rgb_pixel = cv2.cvtColor(hsv_pixel, cv2.COLOR_HSV2RGB)
            image[i, j] = rgb_pixel[0, 0]
    
    return image

def show_lecture3():
    st.title("Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 3: Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙƒØ³Ù„")
    
    # Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù†Ø¸Ø±ÙŠ
    st.markdown("""
    <div class="theory-box">
    <h3>ğŸ“ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù†Ø¸Ø±ÙŠ</h3>
    <p><strong>Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù†Ù‚Ø·ÙŠØ© (Point Operations):</strong> ØªØ·Ø¨Ù‚ Ø¹Ù„Ù‰ ÙƒÙ„ Ø¨ÙƒØ³Ù„ Ø¨Ø´ÙƒÙ„ Ù…Ù†ÙØµÙ„</p>
    <ul>
    <li><strong>Ø§Ù„Ø³Ø·ÙˆØ¹ (Brightness):</strong> Ø¥Ø¶Ø§ÙØ© Ù‚ÙŠÙ…Ø© Ø«Ø§Ø¨ØªØ© Ù„ÙƒÙ„ Ø¨ÙƒØ³Ù„</li>
    <li><strong>Ø§Ù„ØªØ¨Ø§ÙŠÙ† (Contrast):</strong> Ø¶Ø±Ø¨ ÙƒÙ„ Ø¨ÙƒØ³Ù„ ÙÙŠ Ù…Ø¹Ø§Ù…Ù„</li>
    <li><strong>Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø³Ø§Ù„Ø¨Ø© (Negative):</strong> Ø¹ÙƒØ³ Ù‚ÙŠÙ… Ø§Ù„Ø¨ÙƒØ³Ù„Ø§Øª</li>
    <li><strong>Ø§Ù„Ø¹ØªØ¨Ø© (Thresholding):</strong> ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø«Ù†Ø§Ø¦ÙŠØ© (Ø£Ø³ÙˆØ¯/Ø£Ø¨ÙŠØ¶)</li>
    </ul>
    <p><strong>Ø§Ù„ØµÙŠØºØ© Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ©:</strong> Output = Î± Ã— Input + Î²</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠ
    st.markdown("## ğŸ”¬ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠ")
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
    col1, col2 = st.columns([1, 1])
    
    with col1:
        uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø©", type=['png', 'jpg', 'jpeg'], key="lecture3")
    
    with col2:
        use_sample = st.button("Ø§Ø³ØªØ®Ø¯Ù… ØµÙˆØ±Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ©", key="sample3")
    
    if uploaded_file is not None:
        image = load_image(uploaded_file)
        apply_point_operations(image)
    elif use_sample:
        sample_image = create_sample_image()
        apply_point_operations(sample_image)

def apply_point_operations(image):
    """ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù†Ù‚Ø·ÙŠØ©"""
    st.markdown("### âš™ï¸ Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª")
    
    # Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªØ­ÙƒÙ…
    col1, col2 = st.columns(2)
    
    with col1:
        brightness = st.slider("Ø§Ù„Ø³Ø·ÙˆØ¹ (Brightness)", -100, 100, 0)
        contrast = st.slider("Ø§Ù„ØªØ¨Ø§ÙŠÙ† (Contrast)", 0.1, 3.0, 1.0, 0.1)
    
    with col2:
        apply_negative = st.checkbox("ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø³Ø§Ù„Ø¨Ø©")
        threshold_value = st.slider("Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹ØªØ¨Ø© (Threshold)", 0, 255, 127)
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª
    processed_image = image.copy().astype(np.float32)
    
    # Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ†
    processed_image = contrast * processed_image + brightness
    processed_image = np.clip(processed_image, 0, 255).astype(np.uint8)
    
    # Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø³Ø§Ù„Ø¨Ø©
    if apply_negative:
        processed_image = 255 - processed_image
    
    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ÙŠ Ù„Ù„Ø¹ØªØ¨Ø©
    if len(image.shape) == 3:
        gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        gray_processed = cv2.cvtColor(processed_image, cv2.COLOR_RGB2GRAY)
    else:
        gray_image = image
        gray_processed = processed_image
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹ØªØ¨Ø©
    _, threshold_image = cv2.threshold(gray_processed, threshold_value, 255, cv2.THRESH_BINARY)
    
    # ØªØ·Ø¨ÙŠÙ‚ Otsu
    _, otsu_image = cv2.threshold(gray_processed, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    st.markdown("### ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    
    tab1, tab2, tab3 = st.tabs(["Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ†", "Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø³Ø§Ù„Ø¨Ø©", "Ø§Ù„Ø¹ØªØ¨Ø©"])
    
    with tab1:
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©")
            st.image(image, caption="Original", use_column_width=True)
            st.write(f"Ù…ØªÙˆØ³Ø· Ø§Ù„Ù‚ÙŠÙ…: {image.mean():.1f}")
        
        with col2:
            st.subheader("Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„")
            st.image(processed_image, caption=f"Brightness: {brightness}, Contrast: {contrast}", use_column_width=True)
            st.write(f"Ù…ØªÙˆØ³Ø· Ø§Ù„Ù‚ÙŠÙ…: {processed_image.mean():.1f}")
    
    with tab2:
        if apply_negative:
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("Ù‚Ø¨Ù„ Ø§Ù„Ø¹ÙƒØ³")
                temp_image = image.copy().astype(np.float32)
                temp_image = contrast * temp_image + brightness
                temp_image = np.clip(temp_image, 0, 255).astype(np.uint8)
                st.image(temp_image, caption="Before Negative", use_column_width=True)
            
            with col2:
                st.subheader("Ø¨Ø¹Ø¯ Ø§Ù„Ø¹ÙƒØ³")
                st.image(processed_image, caption="After Negative", use_column_width=True)
        else:
            st.info("Ù‚Ù… Ø¨ØªÙØ¹ÙŠÙ„ Ø®ÙŠØ§Ø± 'Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø³Ø§Ù„Ø¨Ø©' Ù„Ø±Ø¤ÙŠØ© Ø§Ù„ØªØ£Ø«ÙŠØ±")
    
    with tab3:
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.subheader("Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø±Ù…Ø§Ø¯ÙŠØ©")
            st.image(gray_processed, caption="Grayscale", use_column_width=True, clamp=True)
        
        with col2:
            st.subheader(f"Ø¹ØªØ¨Ø© ÙŠØ¯ÙˆÙŠØ© ({threshold_value})")
            st.image(threshold_image, caption="Manual Threshold", use_column_width=True, clamp=True)
        
        with col3:
            st.subheader("Ø¹ØªØ¨Ø© Otsu Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©")
            st.image(otsu_image, caption="Otsu Threshold", use_column_width=True, clamp=True)
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…Ù‚Ø§Ø±Ù†Ø©
    st.markdown("### ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…Ù‚Ø§Ø±Ù†Ø©")
    
    stats_col1, stats_col2, stats_col3 = st.columns(3)
    
    with stats_col1:
        st.metric("Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£ØµÙ„ÙŠØ©", f"{image.mean():.1f}")
        st.metric("Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÙŠØ§Ø±ÙŠ Ø£ØµÙ„ÙŠ", f"{image.std():.1f}")
    
    with stats_col2:
        st.metric("Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¹Ø¯Ù„Ø©", f"{processed_image.mean():.1f}")
        st.metric("Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÙŠØ§Ø±ÙŠ Ù…Ø¹Ø¯Ù„", f"{processed_image.std():.1f}")
    
    with stats_col3:
        diff = processed_image.astype(np.float32) - image.astype(np.float32)
        st.metric("Ù…ØªÙˆØ³Ø· Ø§Ù„ÙØ±Ù‚", f"{diff.mean():.1f}")
        st.metric("Ø£Ù‚ØµÙ‰ ÙØ±Ù‚", f"{np.abs(diff).max():.1f}")
    
    # Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„ØªÙˆØ²ÙŠØ¹
    if st.checkbox("Ø¹Ø±Ø¶ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¨ÙƒØ³Ù„Ø§Øª"):
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
        
        # Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
        if len(image.shape) == 3:
            for i, color in enumerate(['red', 'green', 'blue']):
                hist, bins = np.histogram(image[:, :, i].flatten(), bins=50, range=(0, 255))
                ax1.plot(bins[:-1], hist, color=color, alpha=0.7)
        else:
            hist, bins = np.histogram(image.flatten(), bins=50, range=(0, 255))
            ax1.plot(bins[:-1], hist, color='gray')
        
        ax1.set_title('ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©')
        ax1.set_xlabel('Ø´Ø¯Ø© Ø§Ù„Ø¨ÙƒØ³Ù„')
        ax1.set_ylabel('Ø§Ù„ØªÙƒØ±Ø§Ø±')
        
        # Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø¯Ù„Ø©
        if len(processed_image.shape) == 3:
            for i, color in enumerate(['red', 'green', 'blue']):
                hist, bins = np.histogram(processed_image[:, :, i].flatten(), bins=50, range=(0, 255))
                ax2.plot(bins[:-1], hist, color=color, alpha=0.7)
        else:
            hist, bins = np.histogram(processed_image.flatten(), bins=50, range=(0, 255))
            ax2.plot(bins[:-1], hist, color='gray')
        
        ax2.set_title('ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø¯Ù„Ø©')
        ax2.set_xlabel('Ø´Ø¯Ø© Ø§Ù„Ø¨ÙƒØ³Ù„')
        ax2.set_ylabel('Ø§Ù„ØªÙƒØ±Ø§Ø±')
        
        plt.tight_layout()
        st.pyplot(fig)

def show_lecture4():
    st.title("Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 4: Ø§Ù„ÙÙ„Ø§ØªØ± ÙˆØ§Ù„Ø§Ù„ØªÙØ§Ù")
    
    # Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù†Ø¸Ø±ÙŠ
    st.markdown("""
    <div class="theory-box">
    <h3>ğŸ“ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù†Ø¸Ø±ÙŠ</h3>
    <p><strong>Ø§Ù„Ø§Ù„ØªÙØ§Ù (Convolution):</strong> Ø¹Ù…Ù„ÙŠØ© Ø±ÙŠØ§Ø¶ÙŠØ© ØªØ·Ø¨Ù‚ Ù…Ø±Ø´Ø­ (Kernel) Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø©</p>
    <ul>
    <li><strong>Kernel/Mask:</strong> Ù…ØµÙÙˆÙØ© ØµØºÙŠØ±Ø© ØªØ­Ø¯Ø¯ Ù†ÙˆØ¹ Ø§Ù„ØªØ£Ø«ÙŠØ±</li>
    <li><strong>Blur:</strong> ØªÙ†Ø¹ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø© ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©</li>
    <li><strong>Sharpen:</strong> ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø­ÙˆØ§Ù ÙˆØ²ÙŠØ§Ø¯Ø© ÙˆØ¶ÙˆØ­ Ø§Ù„ØªÙØ§ØµÙŠÙ„</li>
    <li><strong>Edge Detection:</strong> ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù ÙˆØ§Ù„Ø§Ù†ØªÙ‚Ø§Ù„Ø§Øª ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©</li>
    </ul>
    <p><strong>Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª:</strong> ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±ØŒ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ØŒ ÙƒØ´Ù Ø§Ù„Ø£Ø´ÙƒØ§Ù„</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠ
    st.markdown("## ğŸ”¬ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠ")
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
    col1, col2 = st.columns([1, 1])
    
    with col1:
        uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø©", type=['png', 'jpg', 'jpeg'], key="lecture4")
    
    with col2:
        use_sample = st.button("Ø§Ø³ØªØ®Ø¯Ù… ØµÙˆØ±Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ©", key="sample4")
    
    if uploaded_file is not None:
        image = load_image(uploaded_file)
        apply_filters(image)
    elif use_sample:
        sample_image = create_detailed_sample_image()
        apply_filters(sample_image)

def apply_filters(image):
    """ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ù…Ø®ØªÙ„ÙØ©"""
    st.markdown("### âš™ï¸ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙÙ„ØªØ±")
    
    # Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ÙÙ„Ø§ØªØ±
    filter_type = st.selectbox(
        "Ù†ÙˆØ¹ Ø§Ù„ÙÙ„ØªØ±:",
        ["Blur", "Gaussian Blur", "Median Blur", "Sharpen", "Edge Detection", "Emboss", "Custom Kernel"]
    )
    
    # Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„ÙÙ„ØªØ±
    col1, col2 = st.columns(2)
    
    with col1:
        if filter_type in ["Blur", "Gaussian Blur", "Median Blur"]:
            kernel_size = st.slider("Ø­Ø¬Ù… Ø§Ù„ÙÙ„ØªØ±", 3, 15, 5, step=2)
        elif filter_type == "Custom Kernel":
            st.subheader("Kernel Ù…Ø®ØµØµ (3x3)")
            kernel = np.zeros((3, 3))
            for i in range(3):
                cols = st.columns(3)
                for j in range(3):
                    with cols[j]:
                        kernel[i, j] = st.number_input(f"[{i},{j}]", value=0.0, format="%.2f", key=f"kernel_{i}_{j}")
    
    with col2:
        if filter_type == "Gaussian Blur":
            sigma = st.slider("Sigma", 0.1, 5.0, 1.0, 0.1)
        elif filter_type == "Edge Detection":
            edge_method = st.selectbox("Ø·Ø±ÙŠÙ‚Ø© ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù:", ["Sobel", "Laplacian", "Scharr"])
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„ØªØ±
    if len(image.shape) == 3:
        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ BGR Ù„Ù„Ø¹Ù…Ù„ Ù…Ø¹ OpenCV
        bgr_image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
    else:
        bgr_image = image
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„ØªØ± Ø§Ù„Ù…Ø­Ø¯Ø¯
    if filter_type == "Blur":
        filtered_image = cv2.blur(bgr_image, (kernel_size, kernel_size))
    elif filter_type == "Gaussian Blur":
        filtered_image = cv2.GaussianBlur(bgr_image, (kernel_size, kernel_size), sigma)
    elif filter_type == "Median Blur":
        filtered_image = cv2.medianBlur(bgr_image, kernel_size)
    elif filter_type == "Sharpen":
        kernel = np.array([[-1, -1, -1],
                          [-1,  9, -1],
                          [-1, -1, -1]])
        filtered_image = cv2.filter2D(bgr_image, -1, kernel)
    elif filter_type == "Edge Detection":
        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ÙŠ Ø£ÙˆÙ„Ø§Ù‹
        if len(bgr_image.shape) == 3:
            gray = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)
        else:
            gray = bgr_image
            
        if edge_method == "Sobel":
            sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
            sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            filtered_image = np.sqrt(sobelx**2 + sobely**2)
        elif edge_method == "Laplacian":
            filtered_image = cv2.Laplacian(gray, cv2.CV_64F)
        elif edge_method == "Scharr":
            scharrx = cv2.Scharr(gray, cv2.CV_64F, 1, 0)
            scharry = cv2.Scharr(gray, cv2.CV_64F, 0, 1)
            filtered_image = np.sqrt(scharrx**2 + scharry**2)
        
        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ uint8
        filtered_image = np.uint8(np.absolute(filtered_image))
    elif filter_type == "Emboss":
        kernel = np.array([[-2, -1,  0],
                          [-1,  1,  1],
                          [ 0,  1,  2]])
        filtered_image = cv2.filter2D(bgr_image, -1, kernel)
    elif filter_type == "Custom Kernel":
        filtered_image = cv2.filter2D(bgr_image, -1, kernel)
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù„Ù„Ø¹Ø±Ø¶
    if len(filtered_image.shape) == 3 and filtered_image.shape[2] == 3:
        display_filtered = cv2.cvtColor(filtered_image, cv2.COLOR_BGR2RGB)
    else:
        display_filtered = filtered_image
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    st.markdown("### ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©")
        st.image(image, caption="Original Image", use_column_width=True)
        st.write(f"Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯: {image.shape}")
        st.write(f"Ù…ØªÙˆØ³Ø· Ø§Ù„Ù‚ÙŠÙ…: {image.mean():.1f}")
    
    with col2:
        st.subheader(f"Ø¨Ø¹Ø¯ ØªØ·Ø¨ÙŠÙ‚ {filter_type}")
        st.image(display_filtered, caption=f"Filtered Image - {filter_type}", use_column_width=True)
        st.write(f"Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯: {display_filtered.shape}")
        st.write(f"Ù…ØªÙˆØ³Ø· Ø§Ù„Ù‚ÙŠÙ…: {display_filtered.mean():.1f}")
    
    # Ø¹Ø±Ø¶ Ø§Ù„ÙØ±Ù‚
    if st.checkbox("Ø¹Ø±Ø¶ Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† Ø§Ù„ØµÙˆØ±"):
        if len(image.shape) == len(display_filtered.shape):
            if len(image.shape) == 3:
                # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ÙŠ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
                gray_original = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
                if len(display_filtered.shape) == 3:
                    gray_filtered = cv2.cvtColor(display_filtered, cv2.COLOR_RGB2GRAY)
                else:
                    gray_filtered = display_filtered
            else:
                gray_original = image
                gray_filtered = display_filtered
            
            diff = np.abs(gray_original.astype(np.float32) - gray_filtered.astype(np.float32))
            st.subheader("Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† Ø§Ù„ØµÙˆØ±")
            st.image(diff, caption="Difference", use_column_width=True, clamp=True)
            st.write(f"Ù…ØªÙˆØ³Ø· Ø§Ù„ÙØ±Ù‚: {diff.mean():.1f}")
            st.write(f"Ø£Ù‚ØµÙ‰ ÙØ±Ù‚: {diff.max():.1f}")
    
    # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙÙ„ØªØ±
    st.markdown("### ğŸ“‹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙÙ„ØªØ±")
    
    if filter_type == "Custom Kernel":
        st.write("**Ø§Ù„Ù€ Kernel Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:**")
        st.write(kernel)
    elif filter_type in ["Blur", "Gaussian Blur", "Median Blur"]:
        st.write(f"**Ø­Ø¬Ù… Ø§Ù„ÙÙ„ØªØ±:** {kernel_size}x{kernel_size}")
        if filter_type == "Gaussian Blur":
            st.write(f"**Sigma:** {sigma}")
    elif filter_type == "Sharpen":
        sharpen_kernel = np.array([[-1, -1, -1],
                                  [-1,  9, -1],
                                  [-1, -1, -1]])
        st.write("**Sharpen Kernel:**")
        st.write(sharpen_kernel)
    elif filter_type == "Emboss":
        emboss_kernel = np.array([[-2, -1,  0],
                                 [-1,  1,  1],
                                 [ 0,  1,  2]])
        st.write("**Emboss Kernel:**")
        st.write(emboss_kernel)

def create_detailed_sample_image():
    """Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ© Ù…ÙØµÙ„Ø© Ù„Ù„ÙÙ„Ø§ØªØ±"""
    height, width = 200, 300
    image = np.zeros((height, width, 3), dtype=np.uint8)
    
    # Ø®Ù„ÙÙŠØ© Ø¨ÙŠØ¶Ø§Ø¡
    image.fill(255)
    
    # Ø¥Ø¶Ø§ÙØ© Ø£Ø´ÙƒØ§Ù„ Ù…Ø®ØªÙ„ÙØ©
    # Ù…Ø±Ø¨Ø¹ Ø£Ø³ÙˆØ¯
    cv2.rectangle(image, (50, 50), (100, 100), (0, 0, 0), -1)
    
    # Ø¯Ø§Ø¦Ø±Ø© Ø­Ù…Ø±Ø§Ø¡
    cv2.circle(image, (200, 75), 30, (255, 0, 0), -1)
    
    # Ø®Ø· Ø£Ø²Ø±Ù‚
    cv2.line(image, (50, 150), (250, 150), (0, 0, 255), 3)
    
    # Ù…Ø«Ù„Ø« Ø£Ø®Ø¶Ø±
    pts = np.array([[150, 120], [120, 180], [180, 180]], np.int32)
    cv2.fillPoly(image, [pts], (0, 255, 0))
    
    # Ø¥Ø¶Ø§ÙØ© Ø¶ÙˆØ¶Ø§Ø¡
    noise = np.random.randint(0, 50, image.shape, dtype=np.uint8)
    image = cv2.add(image, noise)
    
    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

def show_lecture5():
    st.title("Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 5: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡")
    
    # Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù†Ø¸Ø±ÙŠ
    st.markdown("""
    <div class="theory-box">
    <h3>ğŸ“ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù†Ø¸Ø±ÙŠ</h3>
    <p><strong>Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ ÙÙŠ Ø§Ù„ØµÙˆØ±:</strong> Ø¨ÙƒØ³Ù„Ø§Øª ØºÙŠØ± Ù…Ø±ØºÙˆØ¨ ÙÙŠÙ‡Ø§ ØªØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø©</p>
    <ul>
    <li><strong>Salt & Pepper:</strong> Ù†Ù‚Ø§Ø· Ø¨ÙŠØ¶Ø§Ø¡ ÙˆØ³ÙˆØ¯Ø§Ø¡ Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©</li>
    <li><strong>Gaussian Noise:</strong> Ø¶ÙˆØ¶Ø§Ø¡ Ù…ÙˆØ²Ø¹Ø© Ø·Ø¨ÙŠØ¹ÙŠØ§Ù‹</li>
    <li><strong>Median Filter:</strong> ÙØ¹Ø§Ù„ Ø¶Ø¯ Salt & Pepper</li>
    <li><strong>Bilateral Filter:</strong> ÙŠØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ø­ÙˆØ§Ù Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙ†Ø¹ÙŠÙ…</li>
    </ul>
    <p><strong>Ø§Ù„Ù‡Ø¯Ù:</strong> Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ù‡Ù…Ø©</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠ
    st.markdown("## ğŸ”¬ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠ")
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
    col1, col2 = st.columns([1, 1])
    
    with col1:
        uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø©", type=['png', 'jpg', 'jpeg'], key="lecture5")
    
    with col2:
        use_sample = st.button("Ø§Ø³ØªØ®Ø¯Ù… ØµÙˆØ±Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ©", key="sample5")
    
    if uploaded_file is not None:
        image = load_image(uploaded_file)
        apply_denoising(image)
    elif use_sample:
        sample_image = create_sample_image()
        apply_denoising(sample_image)

def apply_denoising(image):
    """ØªØ·Ø¨ÙŠÙ‚ ØªÙ‚Ù†ÙŠØ§Øª Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡"""
    st.markdown("### âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡")
    
    # Ø®ÙŠØ§Ø±Ø§Øª Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
    col1, col2 = st.columns(2)
    
    with col1:
        add_noise = st.checkbox("Ø¥Ø¶Ø§ÙØ© Ø¶ÙˆØ¶Ø§Ø¡ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±")
        if add_noise:
            noise_type = st.selectbox("Ù†ÙˆØ¹ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡:", ["Salt & Pepper", "Gaussian"])
            noise_intensity = st.slider("Ø´Ø¯Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡", 0.01, 0.3, 0.1, 0.01)
    
    with col2:
        denoising_method = st.selectbox(
            "Ø·Ø±ÙŠÙ‚Ø© Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡:",
            ["Median Filter", "Bilateral Filter", "Gaussian Blur", "Non-local Means"]
        )
        
        if denoising_method == "Median Filter":
            kernel_size = st.slider("Ø­Ø¬Ù… Ø§Ù„ÙÙ„ØªØ±", 3, 15, 5, step=2)
        elif denoising_method == "Bilateral Filter":
            d = st.slider("Ù‚Ø·Ø± Ø§Ù„ÙÙ„ØªØ±", 5, 15, 9)
            sigma_color = st.slider("Sigma Color", 10, 150, 75)
            sigma_space = st.slider("Sigma Space", 10, 150, 75)
        elif denoising_method == "Gaussian Blur":
            kernel_size = st.slider("Ø­Ø¬Ù… Ø§Ù„ÙÙ„ØªØ±", 3, 15, 5, step=2)
            sigma = st.slider("Sigma", 0.1, 5.0, 1.0, 0.1)
        elif denoising_method == "Non-local Means":
            h = st.slider("Filter Strength", 3, 20, 10)
            template_window_size = st.slider("Template Window Size", 3, 11, 7, step=2)
            search_window_size = st.slider("Search Window Size", 11, 31, 21, step=2)
    
    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ø¥Ø°Ø§ Ø·ÙÙ„Ø¨ Ø°Ù„Ùƒ
    if add_noise:
        noisy_image = add_noise_to_image(image, noise_type, noise_intensity)
        working_image = noisy_image
    else:
        working_image = image
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
    if len(working_image.shape) == 3:
        bgr_image = cv2.cvtColor(working_image, cv2.COLOR_RGB2BGR)
    else:
        bgr_image = working_image
    
    if denoising_method == "Median Filter":
        denoised_image = cv2.medianBlur(bgr_image, kernel_size)
    elif denoising_method == "Bilateral Filter":
        denoised_image = cv2.bilateralFilter(bgr_image, d, sigma_color, sigma_space)
    elif denoising_method == "Gaussian Blur":
        denoised_image = cv2.GaussianBlur(bgr_image, (kernel_size, kernel_size), sigma)
    elif denoising_method == "Non-local Means":
        if len(bgr_image.shape) == 3:
            denoised_image = cv2.fastNlMeansDenoisingColored(bgr_image, None, h, h, template_window_size, search_window_size)
        else:
            denoised_image = cv2.fastNlMeansDenoising(bgr_image, None, h, template_window_size, search_window_size)
    
    # ØªØ­ÙˆÙŠÙ„ Ù„Ù„Ø¹Ø±Ø¶
    if len(denoised_image.shape) == 3:
        display_denoised = cv2.cvtColor(denoised_image, cv2.COLOR_BGR2RGB)
    else:
        display_denoised = denoised_image
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    st.markdown("### ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    
    if add_noise:
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.subheader("Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©")
            st.image(image, caption="Original", use_column_width=True)
            st.write(f"PSNR: âˆ dB")
        
        with col2:
            st.subheader("Ù…Ø¹ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡")
            st.image(working_image, caption=f"With {noise_type} Noise", use_column_width=True)
            psnr_noisy = calculate_psnr(image, working_image)
            st.write(f"PSNR: {psnr_noisy:.2f} dB")
        
        with col3:
            st.subheader("Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡")
            st.image(display_denoised, caption=f"Denoised - {denoising_method}", use_column_width=True)
            psnr_denoised = calculate_psnr(image, display_denoised)
            st.write(f"PSNR: {psnr_denoised:.2f} dB")
    else:
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©")
            st.image(image, caption="Original", use_column_width=True)
            st.write(f"Ù…ØªÙˆØ³Ø· Ø§Ù„Ù‚ÙŠÙ…: {image.mean():.1f}")
            st.write(f"Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ: {image.std():.1f}")
        
        with col2:
            st.subheader("Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡")
            st.image(display_denoised, caption=f"Denoised - {denoising_method}", use_column_width=True)
            st.write(f"Ù…ØªÙˆØ³Ø· Ø§Ù„Ù‚ÙŠÙ…: {display_denoised.mean():.1f}")
            st.write(f"Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ: {display_denoised.std():.1f}")
    
    # Ù…Ù‚Ø§Ø±Ù†Ø© ØªÙØµÙŠÙ„ÙŠØ©
    st.markdown("### ğŸ“ˆ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡")
    
    metrics_col1, metrics_col2, metrics_col3 = st.columns(3)
    
    with metrics_col1:
        st.metric("ØªØ­Ø³Ù† Ø§Ù„ÙˆØ¶ÙˆØ­", f"{calculate_sharpness_improvement(working_image, display_denoised):.1f}%")
    
    with metrics_col2:
        st.metric("ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡", f"{calculate_noise_reduction(working_image, display_denoised):.1f}%")
    
    with metrics_col3:
        if add_noise:
            st.metric("ØªØ­Ø³Ù† PSNR", f"{psnr_denoised - psnr_noisy:.2f} dB")
        else:
            st.metric("ØªÙ†Ø¹ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø©", f"{working_image.std() - display_denoised.std():.1f}")

def add_noise_to_image(image, noise_type, intensity):
    """Ø¥Ø¶Ø§ÙØ© Ø¶ÙˆØ¶Ø§Ø¡ Ù„Ù„ØµÙˆØ±Ø©"""
    noisy_image = image.copy()
    
    if noise_type == "Salt & Pepper":
        # Ø¥Ø¶Ø§ÙØ© Ø¶ÙˆØ¶Ø§Ø¡ Ù…Ù„Ø­ ÙˆÙÙ„ÙÙ„
        noise = np.random.random(image.shape[:2])
        noisy_image[noise < intensity/2] = 0  # ÙÙ„ÙÙ„ (Ø£Ø³ÙˆØ¯)
        noisy_image[noise > 1 - intensity/2] = 255  # Ù…Ù„Ø­ (Ø£Ø¨ÙŠØ¶)
    
    elif noise_type == "Gaussian":
        # Ø¥Ø¶Ø§ÙØ© Ø¶ÙˆØ¶Ø§Ø¡ ØºØ§ÙˆØ³ÙŠØ©
        mean = 0
        std = intensity * 255
        noise = np.random.normal(mean, std, image.shape).astype(np.uint8)
        noisy_image = cv2.add(image, noise)
    
    return noisy_image

def calculate_psnr(original, processed):
    """Ø­Ø³Ø§Ø¨ PSNR"""
    mse = np.mean((original.astype(np.float32) - processed.astype(np.float32)) ** 2)
    if mse == 0:
        return float('inf')
    max_pixel = 255.0
    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))
    return psnr

def calculate_sharpness_improvement(original, processed):
    """Ø­Ø³Ø§Ø¨ ØªØ­Ø³Ù† Ø§Ù„ÙˆØ¶ÙˆØ­"""
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Laplacian Ù„Ù„Ù‚ÙŠØ§Ø³
    if len(original.shape) == 3:
        gray_orig = cv2.cvtColor(original, cv2.COLOR_RGB2GRAY)
        gray_proc = cv2.cvtColor(processed, cv2.COLOR_RGB2GRAY)
    else:
        gray_orig = original
        gray_proc = processed
    
    laplacian_orig = cv2.Laplacian(gray_orig, cv2.CV_64F).var()
    laplacian_proc = cv2.Laplacian(gray_proc, cv2.CV_64F).var()
    
    if laplacian_orig == 0:
        return 0
    
    improvement = ((laplacian_proc - laplacian_orig) / laplacian_orig) * 100
    return improvement

def calculate_noise_reduction(original, processed):
    """Ø­Ø³Ø§Ø¨ ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡"""
    noise_orig = original.std()
    noise_proc = processed.std()
    
    if noise_orig == 0:
        return 0
    
    reduction = ((noise_orig - noise_proc) / noise_orig) * 100
    return max(0, reduction)  # Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† Ø³Ø§Ù„Ø¨Ø§Ù‹

def show_lecture6():
    st.title("Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 6: ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù")
    
    # Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù†Ø¸Ø±ÙŠ
    st.markdown("""
    <div class="theory-box">
    <h3>ğŸ“ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù†Ø¸Ø±ÙŠ</h3>
    <p><strong>ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù:</strong> ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„ØªÙŠ ØªØªØºÙŠØ± ÙÙŠÙ‡Ø§ Ø´Ø¯Ø© Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø© Ø¨Ø´ÙƒÙ„ Ø­Ø§Ø¯</p>
    <ul>
    <li><strong>Ø§Ù„ØªØ¯Ø±Ø¬ (Gradient):</strong> Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØºÙŠØ± ÙÙŠ Ø´Ø¯Ø© Ø§Ù„Ø¨ÙƒØ³Ù„</li>
    <li><strong>Sobel:</strong> ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù Ø§Ù„Ø£ÙÙ‚ÙŠØ© ÙˆØ§Ù„Ø±Ø£Ø³ÙŠØ©</li>
    <li><strong>Laplacian:</strong> ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª</li>
    <li><strong>Canny:</strong> Ø£ÙØ¶Ù„ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© ÙƒØ´Ù Ø­ÙˆØ§Ù Ù…Ø¹ ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„Ø¹ØªØ¨Ø§Øª</li>
    </ul>
    <p><strong>Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª:</strong> ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø´ÙƒØ§Ù„ØŒ ÙƒØ´Ù Ø§Ù„ÙƒØ§Ø¦Ù†Ø§ØªØŒ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ø·Ø¨ÙŠØ©</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠ
    st.markdown("## ğŸ”¬ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠ")
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
    col1, col2 = st.columns([1, 1])
    
    with col1:
        uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø©", type=['png', 'jpg', 'jpeg'], key="lecture6")
    
    with col2:
        use_sample = st.button("Ø§Ø³ØªØ®Ø¯Ù… ØµÙˆØ±Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ©", key="sample6")
    
    if uploaded_file is not None:
        image = load_image(uploaded_file)
        apply_edge_detection(image)
    elif use_sample:
        sample_image = create_detailed_sample_image()
        apply_edge_detection(sample_image)

def apply_edge_detection(image):
    """ØªØ·Ø¨ÙŠÙ‚ ØªÙ‚Ù†ÙŠØ§Øª ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù"""
    st.markdown("### âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù")
    
    # Ø®ÙŠØ§Ø±Ø§Øª ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù
    col1, col2 = st.columns(2)
    
    with col1:
        edge_method = st.selectbox(
            "Ø·Ø±ÙŠÙ‚Ø© ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù:",
            ["Canny", "Sobel", "Laplacian", "Scharr", "Prewitt", "Roberts"]
        )
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø©
        apply_blur = st.checkbox("ØªØ·Ø¨ÙŠÙ‚ ØªÙ†Ø¹ÙŠÙ… Ù…Ø³Ø¨Ù‚")
        if apply_blur:
            blur_kernel = st.slider("Ø­Ø¬Ù… ÙÙ„ØªØ± Ø§Ù„ØªÙ†Ø¹ÙŠÙ…", 3, 15, 5, step=2)
    
    with col2:
        if edge_method == "Canny":
            threshold1 = st.slider("Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ø³ÙÙ„Ù‰", 0, 255, 50)
            threshold2 = st.slider("Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ø¹Ù„ÙŠØ§", 0, 255, 150)
            aperture_size = st.selectbox("Ø­Ø¬Ù… Aperture", [3, 5, 7])
        elif edge_method in ["Sobel", "Scharr"]:
            ksize = st.selectbox("Ø­Ø¬Ù… Kernel", [1, 3, 5, 7]) if edge_method == "Sobel" else 3
            show_direction = st.selectbox("Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø±Ø¶:", ["Combined", "X Direction", "Y Direction", "Both Separate"])
        elif edge_method == "Laplacian":
            ksize = st.selectbox("Ø­Ø¬Ù… Kernel", [1, 3, 5, 7])
    
    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ÙŠ
    if len(image.shape) == 3:
        gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    else:
        gray_image = image
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙ†Ø¹ÙŠÙ… Ø§Ù„Ù…Ø³Ø¨Ù‚ Ø¥Ø°Ø§ Ø·ÙÙ„Ø¨
    if apply_blur:
        working_image = cv2.GaussianBlur(gray_image, (blur_kernel, blur_kernel), 0)
    else:
        working_image = gray_image
    
    # ØªØ·Ø¨ÙŠÙ‚ ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù
    if edge_method == "Canny":
        edges = cv2.Canny(working_image, threshold1, threshold2, apertureSize=aperture_size)
        
    elif edge_method == "Sobel":
        sobelx = cv2.Sobel(working_image, cv2.CV_64F, 1, 0, ksize=ksize)
        sobely = cv2.Sobel(working_image, cv2.CV_64F, 0, 1, ksize=ksize)
        
        if show_direction == "Combined":
            edges = np.sqrt(sobelx**2 + sobely**2)
        elif show_direction == "X Direction":
            edges = np.abs(sobelx)
        elif show_direction == "Y Direction":
            edges = np.abs(sobely)
        
        edges = np.uint8(np.clip(edges, 0, 255))
        
    elif edge_method == "Scharr":
        scharrx = cv2.Scharr(working_image, cv2.CV_64F, 1, 0)
        scharry = cv2.Scharr(working_image, cv2.CV_64F, 0, 1)
        
        if show_direction == "Combined":
            edges = np.sqrt(scharrx**2 + scharry**2)
        elif show_direction == "X Direction":
            edges = np.abs(scharrx)
        elif show_direction == "Y Direction":
            edges = np.abs(scharry)
        
        edges = np.uint8(np.clip(edges, 0, 255))
        
    elif edge_method == "Laplacian":
        edges = cv2.Laplacian(working_image, cv2.CV_64F, ksize=ksize)
        edges = np.uint8(np.absolute(edges))
        
    elif edge_method == "Prewitt":
        # ØªØ·Ø¨ÙŠÙ‚ Ù…Ø±Ø´Ø­Ø§Øª Prewitt
        kernelx = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]], dtype=np.float32)
        kernely = np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]], dtype=np.float32)
        
        prewittx = cv2.filter2D(working_image, cv2.CV_32F, kernelx)
        prewitty = cv2.filter2D(working_image, cv2.CV_32F, kernely)
        
        edges = np.sqrt(prewittx**2 + prewitty**2)
        edges = np.uint8(np.clip(edges, 0, 255))
        
    elif edge_method == "Roberts":
        # ØªØ·Ø¨ÙŠÙ‚ Ù…Ø±Ø´Ø­Ø§Øª Roberts
        kernelx = np.array([[1, 0], [0, -1]], dtype=np.float32)
        kernely = np.array([[0, 1], [-1, 0]], dtype=np.float32)
        
        robertsx = cv2.filter2D(working_image, cv2.CV_32F, kernelx)
        robertsy = cv2.filter2D(working_image, cv2.CV_32F, kernely)
        
        edges = np.sqrt(robertsx**2 + robertsy**2)
        edges = np.uint8(np.clip(edges, 0, 255))
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    st.markdown("### ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    
    if edge_method in ["Sobel", "Scharr"] and show_direction == "Both Separate":
        # Ø¹Ø±Ø¶ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ù…Ù†ÙØµÙ„Ø©
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.subheader("Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©")
            st.image(image, caption="Original", use_column_width=True)
        
        with col2:
            st.subheader("Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø£ÙÙ‚ÙŠ (X)")
            if edge_method == "Sobel":
                edge_x = np.uint8(np.absolute(sobelx))
            else:
                edge_x = np.uint8(np.absolute(scharrx))
            st.image(edge_x, caption="X Direction", use_column_width=True, clamp=True)
        
        with col3:
            st.subheader("Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø±Ø£Ø³ÙŠ (Y)")
            if edge_method == "Sobel":
                edge_y = np.uint8(np.absolute(sobely))
            else:
                edge_y = np.uint8(np.absolute(scharry))
            st.image(edge_y, caption="Y Direction", use_column_width=True, clamp=True)
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©
        st.subheader("Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©")
        combined_edges = np.sqrt((edge_x.astype(np.float32))**2 + (edge_y.astype(np.float32))**2)
        combined_edges = np.uint8(np.clip(combined_edges, 0, 255))
        st.image(combined_edges, caption="Combined Result", use_column_width=True, clamp=True)
        
    else:
        # Ø¹Ø±Ø¶ Ø¹Ø§Ø¯ÙŠ
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©")
            st.image(image, caption="Original Image", use_column_width=True)
            st.write(f"Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯: {image.shape}")
        
        with col2:
            st.subheader(f"ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù - {edge_method}")
            st.image(edges, caption=f"Edges - {edge_method}", use_column_width=True, clamp=True)
            st.write(f"Ø¹Ø¯Ø¯ Ù†Ù‚Ø§Ø· Ø§Ù„Ø­ÙˆØ§Ù: {np.count_nonzero(edges):,}")
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø­ÙˆØ§Ù
    st.markdown("### ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø­ÙˆØ§Ù")
    
    stats_col1, stats_col2, stats_col3 = st.columns(3)
    
    with stats_col1:
        edge_pixels = np.count_nonzero(edges)
        total_pixels = edges.size
        edge_percentage = (edge_pixels / total_pixels) * 100
        st.metric("Ù†Ø³Ø¨Ø© Ø§Ù„Ø­ÙˆØ§Ù", f"{edge_percentage:.2f}%")
    
    with stats_col2:
        st.metric("Ø´Ø¯Ø© Ø§Ù„Ø­ÙˆØ§Ù Ø§Ù„Ù…ØªÙˆØ³Ø·Ø©", f"{edges[edges > 0].mean():.1f}" if edge_pixels > 0 else "0")
    
    with stats_col3:
        st.metric("Ø£Ù‚ØµÙ‰ Ø´Ø¯Ø© Ø­Ø§ÙØ©", f"{edges.max()}")
    
    # Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„Ø·Ø±Ù‚ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
    if st.checkbox("Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø·Ø±Ù‚ Ù…Ø®ØªÙ„ÙØ©"):
        st.markdown("### ğŸ” Ù…Ù‚Ø§Ø±Ù†Ø© Ø·Ø±Ù‚ ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù")
        
        methods = ["Canny", "Sobel", "Laplacian", "Scharr"]
        cols = st.columns(len(methods))
        
        for i, method in enumerate(methods):
            with cols[i]:
                if method == "Canny":
                    result = cv2.Canny(working_image, 50, 150)
                elif method == "Sobel":
                    sobelx = cv2.Sobel(working_image, cv2.CV_64F, 1, 0, ksize=3)
                    sobely = cv2.Sobel(working_image, cv2.CV_64F, 0, 1, ksize=3)
                    result = np.uint8(np.sqrt(sobelx**2 + sobely**2))
                elif method == "Laplacian":
                    result = np.uint8(np.absolute(cv2.Laplacian(working_image, cv2.CV_64F)))
                elif method == "Scharr":
                    scharrx = cv2.Scharr(working_image, cv2.CV_64F, 1, 0)
                    scharry = cv2.Scharr(working_image, cv2.CV_64F, 0, 1)
                    result = np.uint8(np.sqrt(scharrx**2 + scharry**2))
                
                st.subheader(method)
                st.image(result, caption=method, use_column_width=True, clamp=True)
                edge_count = np.count_nonzero(result)
                st.write(f"Ù†Ù‚Ø§Ø· Ø§Ù„Ø­ÙˆØ§Ù: {edge_count:,}")
    
    # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªÙ‚Ù†ÙŠØ©
    st.markdown("### ğŸ“‹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªÙ‚Ù†ÙŠØ©")
    
    info_text = f"""
    **Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©:** {edge_method}
    
    **Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª:**
    """
    
    if edge_method == "Canny":
        info_text += f"""
    - Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ø³ÙÙ„Ù‰: {threshold1}
    - Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ø¹Ù„ÙŠØ§: {threshold2}
    - Ø­Ø¬Ù… Aperture: {aperture_size}
    """
    elif edge_method in ["Sobel", "Laplacian"]:
        info_text += f"""
    - Ø­Ø¬Ù… Kernel: {ksize}
    """
    
    if apply_blur:
        info_text += f"""
    - ØªÙ†Ø¹ÙŠÙ… Ù…Ø³Ø¨Ù‚: Ù†Ø¹Ù… (Ø­Ø¬Ù… {blur_kernel})
    """
    else:
        info_text += """
    - ØªÙ†Ø¹ÙŠÙ… Ù…Ø³Ø¨Ù‚: Ù„Ø§
    """
    
    st.markdown(info_text)

def show_lecture7():
    st.title("Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 7: Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©")
    
    # Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù†Ø¸Ø±ÙŠ
    st.markdown("""
    <div class="theory-box">
    <h3>ğŸ“ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù†Ø¸Ø±ÙŠ</h3>
    <p><strong>Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©:</strong> ØªØ·Ø¨Ù‚ Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠØ© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø´ÙƒØ§Ù„</p>
    <ul>
    <li><strong>Erosion:</strong> ØªØ¢ÙƒÙ„ - ÙŠÙ‚Ù„Ù„ Ø­Ø¬Ù… Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡</li>
    <li><strong>Dilation:</strong> ØªÙˆØ³Ø¹ - ÙŠØ²ÙŠØ¯ Ø­Ø¬Ù… Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡</li>
    <li><strong>Opening:</strong> ÙØªØ­ = Erosion Ø«Ù… Dilation - ÙŠØ²ÙŠÙ„ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ø§Ù„ØµØºÙŠØ±Ø©</li>
    <li><strong>Closing:</strong> Ø¥ØºÙ„Ø§Ù‚ = Dilation Ø«Ù… Erosion - ÙŠÙ…Ù„Ø£ Ø§Ù„Ø«Ù‚ÙˆØ¨ Ø§Ù„ØµØºÙŠØ±Ø©</li>
    </ul>
    <p><strong>Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª:</strong> ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠØ©ØŒ ÙØµÙ„ Ø§Ù„ÙƒØ§Ø¦Ù†Ø§ØªØŒ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø´ÙƒØ§Ù„</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠ
    st.markdown("## ğŸ”¬ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠ")
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
    col1, col2 = st.columns([1, 1])
    
    with col1:
        uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø©", type=['png', 'jpg', 'jpeg'], key="lecture7")
    
    with col2:
        use_sample = st.button("Ø§Ø³ØªØ®Ø¯Ù… ØµÙˆØ±Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ©", key="sample7")
    
    if uploaded_file is not None:
        image = load_image(uploaded_file)
        apply_morphological_operations(image)
    elif use_sample:
        sample_image = create_binary_sample_image()
        apply_morphological_operations(sample_image)

def apply_morphological_operations(image):
    """ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©"""
    st.markdown("### âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©")
    
    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØµÙˆØ±Ø© Ø«Ù†Ø§Ø¦ÙŠØ©
    if len(image.shape) == 3:
        gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    else:
        gray_image = image
    
    # Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø«Ù†Ø§Ø¦ÙŠ
    col1, col2 = st.columns(2)
    
    with col1:
        threshold_method = st.selectbox("Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø«Ù†Ø§Ø¦ÙŠ:", ["Manual", "Otsu", "Adaptive"])
        if threshold_method == "Manual":
            threshold_value = st.slider("Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹ØªØ¨Ø©", 0, 255, 127)
        elif threshold_method == "Adaptive":
            block_size = st.slider("Ø­Ø¬Ù… Ø§Ù„Ø¨Ù„ÙˆÙƒ", 3, 21, 11, step=2)
            c_value = st.slider("Ù‚ÙŠÙ…Ø© C", -10, 10, 2)
    
    with col2:
        morph_operation = st.selectbox(
            "Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©:",
            ["Erosion", "Dilation", "Opening", "Closing", "Gradient", "Top Hat", "Black Hat"]
        )
        
        kernel_shape = st.selectbox("Ø´ÙƒÙ„ Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø¨Ù†Ø§Ø¦ÙŠ:", ["Rectangle", "Ellipse", "Cross"])
        kernel_size = st.slider("Ø­Ø¬Ù… Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø¨Ù†Ø§Ø¦ÙŠ", 3, 15, 5, step=2)
        iterations = st.slider("Ø¹Ø¯Ø¯ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª", 1, 5, 1)
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø«Ù†Ø§Ø¦ÙŠ
    if threshold_method == "Manual":
        _, binary_image = cv2.threshold(gray_image, threshold_value, 255, cv2.THRESH_BINARY)
    elif threshold_method == "Otsu":
        _, binary_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    elif threshold_method == "Adaptive":
        binary_image = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, block_size, c_value)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø¨Ù†Ø§Ø¦ÙŠ
    if kernel_shape == "Rectangle":
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))
    elif kernel_shape == "Ellipse":
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
    elif kernel_shape == "Cross":
        kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (kernel_size, kernel_size))
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©
    if morph_operation == "Erosion":
        result = cv2.erode(binary_image, kernel, iterations=iterations)
    elif morph_operation == "Dilation":
        result = cv2.dilate(binary_image, kernel, iterations=iterations)
    elif morph_operation == "Opening":
        result = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel, iterations=iterations)
    elif morph_operation == "Closing":
        result = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel, iterations=iterations)
    elif morph_operation == "Gradient":
        result = cv2.morphologyEx(binary_image, cv2.MORPH_GRADIENT, kernel, iterations=iterations)
    elif morph_operation == "Top Hat":
        result = cv2.morphologyEx(binary_image, cv2.MORPH_TOPHAT, kernel, iterations=iterations)
    elif morph_operation == "Black Hat":
        result = cv2.morphologyEx(binary_image, cv2.MORPH_BLACKHAT, kernel, iterations=iterations)
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    st.markdown("### ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.subheader("Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©")
        st.image(image, caption="Original", use_column_width=True)
    
    with col2:
        st.subheader("Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠØ©")
        st.image(binary_image, caption=f"Binary - {threshold_method}", use_column_width=True, clamp=True)
    
    with col3:
        st.subheader(f"Ø¨Ø¹Ø¯ {morph_operation}")
        st.image(result, caption=f"{morph_operation} Result", use_column_width=True, clamp=True)
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    st.markdown("### ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª")
    
    stats_col1, stats_col2, stats_col3 = st.columns(3)
    
    with stats_col1:
        white_pixels_original = np.count_nonzero(binary_image)
        total_pixels = binary_image.size
        white_percentage_original = (white_pixels_original / total_pixels) * 100
        st.metric("Ø§Ù„Ø¨ÙƒØ³Ù„Ø§Øª Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡ Ø§Ù„Ø£ØµÙ„ÙŠØ©", f"{white_percentage_original:.1f}%")
    
    with stats_col2:
        white_pixels_result = np.count_nonzero(result)
        white_percentage_result = (white_pixels_result / total_pixels) * 100
        st.metric("Ø§Ù„Ø¨ÙƒØ³Ù„Ø§Øª Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡ Ø¨Ø¹Ø¯ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©", f"{white_percentage_result:.1f}%")
    
    with stats_col3:
        change = white_percentage_result - white_percentage_original
        st.metric("Ø§Ù„ØªØºÙŠÙŠØ±", f"{change:+.1f}%")
    
    # Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
    if st.checkbox("Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©"):
        st.markdown("### ğŸ” Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©")
        
        operations = ["Erosion", "Dilation", "Opening", "Closing"]
        cols = st.columns(len(operations))
        
        for i, op in enumerate(operations):
            with cols[i]:
                if op == "Erosion":
                    op_result = cv2.erode(binary_image, kernel, iterations=1)
                elif op == "Dilation":
                    op_result = cv2.dilate(binary_image, kernel, iterations=1)
                elif op == "Opening":
                    op_result = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel)
                elif op == "Closing":
                    op_result = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel)
                
                st.subheader(op)
                st.image(op_result, caption=op, use_column_width=True, clamp=True)
                white_count = np.count_nonzero(op_result)
                st.write(f"Ø¨ÙƒØ³Ù„Ø§Øª Ø¨ÙŠØ¶Ø§Ø¡: {white_count:,}")
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø¨Ù†Ø§Ø¦ÙŠ
    st.markdown("### ğŸ”§ Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø¨Ù†Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
    
    # ØªÙƒØ¨ÙŠØ± Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø¨Ù†Ø§Ø¦ÙŠ Ù„Ù„Ø¹Ø±Ø¶
    display_kernel = cv2.resize(kernel.astype(np.uint8) * 255, (100, 100), interpolation=cv2.INTER_NEAREST)
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.image(display_kernel, caption=f"{kernel_shape} Kernel ({kernel_size}x{kernel_size})", clamp=True)
    
    with col2:
        st.write("**Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø¨Ù†Ø§Ø¦ÙŠ:**")
        st.write(f"- Ø§Ù„Ø´ÙƒÙ„: {kernel_shape}")
        st.write(f"- Ø§Ù„Ø­Ø¬Ù…: {kernel_size}x{kernel_size}")
        st.write(f"- Ø¹Ø¯Ø¯ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª: {iterations}")
        st.write("**Ø§Ù„Ù…ØµÙÙˆÙØ©:**")
        st.write(kernel)
    
    # ØªØ£Ø«ÙŠØ±Ø§Øª Ù…ØªØªØ§Ù„ÙŠØ©
    if st.checkbox("Ø¹Ø±Ø¶ ØªØ£Ø«ÙŠØ±Ø§Øª Ù…ØªØªØ§Ù„ÙŠØ©"):
        st.markdown("### ğŸ”„ ØªØ£Ø«ÙŠØ±Ø§Øª Ù…ØªØªØ§Ù„ÙŠØ©")
        
        st.write("**Opening Ø«Ù… Closing:**")
        opening_result = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel)
        opening_closing_result = cv2.morphologyEx(opening_result, cv2.MORPH_CLOSE, kernel)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.image(binary_image, caption="Original Binary", use_column_width=True, clamp=True)
        with col2:
            st.image(opening_result, caption="After Opening", use_column_width=True, clamp=True)
        with col3:
            st.image(opening_closing_result, caption="After Opening + Closing", use_column_width=True, clamp=True)
        
        st.write("**Closing Ø«Ù… Opening:**")
        closing_result = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel)
        closing_opening_result = cv2.morphologyEx(closing_result, cv2.MORPH_OPEN, kernel)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.image(binary_image, caption="Original Binary", use_column_width=True, clamp=True)
        with col2:
            st.image(closing_result, caption="After Closing", use_column_width=True, clamp=True)
        with col3:
            st.image(closing_opening_result, caption="After Closing + Opening", use_column_width=True, clamp=True)

def create_binary_sample_image():
    """Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ© Ù„Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©"""
    height, width = 200, 300
    image = np.zeros((height, width), dtype=np.uint8)
    
    # Ø¥Ø¶Ø§ÙØ© Ø£Ø´ÙƒØ§Ù„ Ù…Ø®ØªÙ„ÙØ©
    # Ù…Ø±Ø¨Ø¹Ø§Øª
    cv2.rectangle(image, (50, 50), (100, 100), 255, -1)
    cv2.rectangle(image, (150, 50), (200, 100), 255, -1)
    
    # Ø¯ÙˆØ§Ø¦Ø±
    cv2.circle(image, (75, 150), 25, 255, -1)
    cv2.circle(image, (175, 150), 20, 255, -1)
    
    # Ø®Ø·ÙˆØ· Ø±ÙÙŠØ¹Ø©
    cv2.line(image, (20, 20), (280, 20), 255, 2)
    cv2.line(image, (20, 180), (280, 180), 255, 1)
    
    # Ø¥Ø¶Ø§ÙØ© Ø¶ÙˆØ¶Ø§Ø¡ ØµØºÙŠØ±Ø©
    for _ in range(20):
        x = np.random.randint(0, width)
        y = np.random.randint(0, height)
        cv2.circle(image, (x, y), 2, 255, -1)
    
    # Ø¥Ø¶Ø§ÙØ© Ø«Ù‚ÙˆØ¨ ØµØºÙŠØ±Ø© ÙÙŠ Ø§Ù„Ø£Ø´ÙƒØ§Ù„
    cv2.circle(image, (75, 75), 5, 0, -1)
    cv2.circle(image, (175, 75), 3, 0, -1)
    
    return image

def show_lecture8():
    st.title("Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 8: Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ©")
    
    # Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù†Ø¸Ø±ÙŠ
    st.markdown("""
    <div class="theory-box">
    <h3>ğŸ“ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ù†Ø¸Ø±ÙŠ</h3>
    <p><strong>Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ©:</strong> ØªØºÙŠÙŠØ± Ù…ÙˆØ¶Ø¹ Ø£Ùˆ Ø­Ø¬Ù… Ø£Ùˆ Ø§ØªØ¬Ø§Ù‡ Ø§Ù„ØµÙˆØ±Ø©</p>
    <ul>
    <li><strong>Translation:</strong> Ø¥Ø²Ø§Ø­Ø© - Ù†Ù‚Ù„ Ø§Ù„ØµÙˆØ±Ø© ÙÙŠ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª X Ùˆ Y</li>
    <li><strong>Rotation:</strong> Ø¯ÙˆØ±Ø§Ù† - ØªØ¯ÙˆÙŠØ± Ø§Ù„ØµÙˆØ±Ø© Ø­ÙˆÙ„ Ù†Ù‚Ø·Ø© Ù…Ø¹ÙŠÙ†Ø©</li>
    <li><strong>Scaling:</strong> ØªÙƒØ¨ÙŠØ±/ØªØµØºÙŠØ± - ØªØºÙŠÙŠØ± Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø©</li>
    <li><strong>Flipping:</strong> Ø§Ù†Ø¹ÙƒØ§Ø³ - Ù‚Ù„Ø¨ Ø§Ù„ØµÙˆØ±Ø© Ø£ÙÙ‚ÙŠØ§Ù‹ Ø£Ùˆ Ø±Ø£Ø³ÙŠØ§Ù‹</li>
    </ul>
    <p><strong>Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª:</strong> ØªØµØ­ÙŠØ­ Ø§Ù„ØµÙˆØ±ØŒ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¹Ø±Ø¶ØŒ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠ
    st.markdown("## ğŸ”¬ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠ")
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
    col1, col2 = st.columns([1, 1])
    
    with col1:
        uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø©", type=['png', 'jpg', 'jpeg'], key="lecture8")
    
    with col2:
        use_sample = st.button("Ø§Ø³ØªØ®Ø¯Ù… ØµÙˆØ±Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ©", key="sample8")
    
    if uploaded_file is not None:
        image = load_image(uploaded_file)
        apply_geometric_transforms(image)
    elif use_sample:
        sample_image = create_sample_image()
        apply_geometric_transforms(sample_image)

def apply_geometric_transforms(image):
    """ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ©"""
    st.markdown("### âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ©")
    
    # Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØ­ÙˆÙŠÙ„
    transform_type = st.selectbox(
        "Ù†ÙˆØ¹ Ø§Ù„ØªØ­ÙˆÙŠÙ„:",
        ["Translation", "Rotation", "Scaling", "Flipping", "Cropping", "Affine Transform"]
    )
    
    height, width = image.shape[:2]
    
    # Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
    if transform_type == "Translation":
        col1, col2 = st.columns(2)
        with col1:
            tx = st.slider("Ø§Ù„Ø¥Ø²Ø§Ø­Ø© Ø§Ù„Ø£ÙÙ‚ÙŠØ© (X)", -width//2, width//2, 0)
        with col2:
            ty = st.slider("Ø§Ù„Ø¥Ø²Ø§Ø­Ø© Ø§Ù„Ø±Ø£Ø³ÙŠØ© (Y)", -height//2, height//2, 0)
        
        # Ù…ØµÙÙˆÙØ© Ø§Ù„ØªØ­ÙˆÙŠÙ„
        M = np.float32([[1, 0, tx], [0, 1, ty]])
        transformed = cv2.warpAffine(image, M, (width, height))
        
    elif transform_type == "Rotation":
        col1, col2, col3 = st.columns(3)
        with col1:
            angle = st.slider("Ø²Ø§ÙˆÙŠØ© Ø§Ù„Ø¯ÙˆØ±Ø§Ù† (Ø¯Ø±Ø¬Ø©)", -180, 180, 0)
        with col2:
            scale = st.slider("Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„ØªÙƒØ¨ÙŠØ±", 0.1, 2.0, 1.0, 0.1)
        with col3:
            center_x = st.slider("Ù…Ø±ÙƒØ² Ø§Ù„Ø¯ÙˆØ±Ø§Ù† X", 0, width, width//2)
            center_y = st.slider("Ù…Ø±ÙƒØ² Ø§Ù„Ø¯ÙˆØ±Ø§Ù† Y", 0, height, height//2)
        
        # Ù…ØµÙÙˆÙØ© Ø§Ù„ØªØ­ÙˆÙŠÙ„
        center = (center_x, center_y)
        M = cv2.getRotationMatrix2D(center, angle, scale)
        transformed = cv2.warpAffine(image, M, (width, height))
        
    elif transform_type == "Scaling":
        col1, col2 = st.columns(2)
        with col1:
            scale_x = st.slider("Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„ØªÙƒØ¨ÙŠØ± Ø§Ù„Ø£ÙÙ‚ÙŠ", 0.1, 3.0, 1.0, 0.1)
        with col2:
            scale_y = st.slider("Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„ØªÙƒØ¨ÙŠØ± Ø§Ù„Ø±Ø£Ø³ÙŠ", 0.1, 3.0, 1.0, 0.1)
        
        new_width = int(width * scale_x)
        new_height = int(height * scale_y)
        transformed = cv2.resize(image, (new_width, new_height))
        
    elif transform_type == "Flipping":
        flip_direction = st.selectbox("Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø§Ù†Ø¹ÙƒØ§Ø³:", ["Ø£ÙÙ‚ÙŠ", "Ø±Ø£Ø³ÙŠ", "ÙƒÙ„Ø§Ù‡Ù…Ø§"])
        
        if flip_direction == "Ø£ÙÙ‚ÙŠ":
            transformed = cv2.flip(image, 1)
        elif flip_direction == "Ø±Ø£Ø³ÙŠ":
            transformed = cv2.flip(image, 0)
        elif flip_direction == "ÙƒÙ„Ø§Ù‡Ù…Ø§":
            transformed = cv2.flip(image, -1)
            
    elif transform_type == "Cropping":
        col1, col2 = st.columns(2)
        with col1:
            x1 = st.slider("X Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©", 0, width-1, 0)
            y1 = st.slider("Y Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©", 0, height-1, 0)
        with col2:
            x2 = st.slider("X Ø§Ù„Ù†Ù‡Ø§ÙŠØ©", x1+1, width, width)
            y2 = st.slider("Y Ø§Ù„Ù†Ù‡Ø§ÙŠØ©", y1+1, height, height)
        
        transformed = image[y1:y2, x1:x2]
        
    elif transform_type == "Affine Transform":
        st.write("**ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†Ù‚Ø§Ø· Ù„Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£ÙÙŠÙ†ÙŠ:**")
        
        # Ù†Ù‚Ø§Ø· Ø§Ù„Ù…ØµØ¯Ø± (Ø§ÙØªØ±Ø§Ø¶ÙŠØ©)
        src_points = np.float32([[0, 0], [width-1, 0], [0, height-1]])
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.write("Ø§Ù„Ù†Ù‚Ø·Ø© 1:")
            dst_x1 = st.slider("X1", 0, width-1, 0, key="dst_x1")
            dst_y1 = st.slider("Y1", 0, height-1, 0, key="dst_y1")
        
        with col2:
            st.write("Ø§Ù„Ù†Ù‚Ø·Ø© 2:")
            dst_x2 = st.slider("X2", 0, width-1, width-1, key="dst_x2")
            dst_y2 = st.slider("Y2", 0, height-1, 0, key="dst_y2")
        
        with col3:
            st.write("Ø§Ù„Ù†Ù‚Ø·Ø© 3:")
            dst_x3 = st.slider("X3", 0, width-1, 0, key="dst_x3")
            dst_y3 = st.slider("Y3", 0, height-1, height-1, key="dst_y3")
        
        dst_points = np.float32([[dst_x1, dst_y1], [dst_x2, dst_y2], [dst_x3, dst_y3]])
        
        # Ù…ØµÙÙˆÙØ© Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£ÙÙŠÙ†ÙŠ
        M = cv2.getAffineTransform(src_points, dst_points)
        transformed = cv2.warpAffine(image, M, (width, height))
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    st.markdown("### ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©")
        st.image(image, caption="Original Image", use_column_width=True)
        st.write(f"Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯: {image.shape}")
    
    with col2:
        st.subheader(f"Ø¨Ø¹Ø¯ {transform_type}")
        st.image(transformed, caption=f"Transformed - {transform_type}", use_column_width=True)
        st.write(f"Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯: {transformed.shape}")
    
    # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ­ÙˆÙŠÙ„
    st.markdown("### ğŸ“‹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ­ÙˆÙŠÙ„")
    
    info_col1, info_col2 = st.columns(2)
    
    with info_col1:
        st.write(f"**Ù†ÙˆØ¹ Ø§Ù„ØªØ­ÙˆÙŠÙ„:** {transform_type}")
        
        if transform_type == "Translation":
            st.write(f"**Ø§Ù„Ø¥Ø²Ø§Ø­Ø©:** ({tx}, {ty})")
        elif transform_type == "Rotation":
            st.write(f"**Ø§Ù„Ø²Ø§ÙˆÙŠØ©:** {angle}Â°")
            st.write(f"**Ø§Ù„Ù…Ø±ÙƒØ²:** ({center_x}, {center_y})")
            st.write(f"**Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„ØªÙƒØ¨ÙŠØ±:** {scale}")
        elif transform_type == "Scaling":
            st.write(f"**Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„ØªÙƒØ¨ÙŠØ±:** ({scale_x}, {scale_y})")
        elif transform_type == "Flipping":
            st.write(f"**Ø§Ù„Ø§ØªØ¬Ø§Ù‡:** {flip_direction}")
        elif transform_type == "Cropping":
            st.write(f"**Ø§Ù„Ù…Ù†Ø·Ù‚Ø©:** ({x1}, {y1}) Ø¥Ù„Ù‰ ({x2}, {y2})")
    
    with info_col2:
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØºÙŠÙŠØ± ÙÙŠ Ø§Ù„Ø­Ø¬Ù…
        original_size = image.shape[0] * image.shape[1]
        transformed_size = transformed.shape[0] * transformed.shape[1]
        size_change = ((transformed_size - original_size) / original_size) * 100
        
        st.write(f"**Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ø£ØµÙ„ÙŠ:** {original_size:,} Ø¨ÙƒØ³Ù„")
        st.write(f"**Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯:** {transformed_size:,} Ø¨ÙƒØ³Ù„")
        st.write(f"**Ø§Ù„ØªØºÙŠÙŠØ±:** {size_change:+.1f}%")
    
    # Ù…Ù‚Ø§Ø±Ù†Ø© Ù…ØªØ¹Ø¯Ø¯Ø©
    if st.checkbox("Ù…Ù‚Ø§Ø±Ù†Ø© ØªØ­ÙˆÙŠÙ„Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©"):
        st.markdown("### ğŸ” Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©")
        
        transforms = {
            "Ø§Ù„Ø£ØµÙ„ÙŠØ©": image,
            "Ø¯ÙˆØ±Ø§Ù† 45Â°": cv2.warpAffine(image, cv2.getRotationMatrix2D((width//2, height//2), 45, 1), (width, height)),
            "Ø§Ù†Ø¹ÙƒØ§Ø³ Ø£ÙÙ‚ÙŠ": cv2.flip(image, 1),
            "ØªÙƒØ¨ÙŠØ± 1.5x": cv2.resize(image, (int(width*1.5), int(height*1.5)))
        }
        
        cols = st.columns(len(transforms))
        
        for i, (name, img) in enumerate(transforms.items()):
            with cols[i]:
                st.subheader(name)
                st.image(img, caption=name, use_column_width=True)
                st.write(f"Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯: {img.shape[:2]}")
    
    # ØªØ­ÙˆÙŠÙ„Ø§Øª Ù…ØªØªØ§Ù„ÙŠØ©
    if st.checkbox("ØªØ·Ø¨ÙŠÙ‚ ØªØ­ÙˆÙŠÙ„Ø§Øª Ù…ØªØªØ§Ù„ÙŠØ©"):
        st.markdown("### ğŸ”„ ØªØ­ÙˆÙŠÙ„Ø§Øª Ù…ØªØªØ§Ù„ÙŠØ©")
        
        # ØªØ·Ø¨ÙŠÙ‚ Ø³Ù„Ø³Ù„Ø© Ù…Ù† Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª
        step1 = cv2.flip(image, 1)  # Ø§Ù†Ø¹ÙƒØ§Ø³ Ø£ÙÙ‚ÙŠ
        step2 = cv2.warpAffine(step1, cv2.getRotationMatrix2D((width//2, height//2), 30, 1), (width, height))  # Ø¯ÙˆØ±Ø§Ù†
        step3 = cv2.resize(step2, (int(width*0.8), int(height*0.8)))  # ØªØµØºÙŠØ±
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.subheader("Ø§Ù„Ø£ØµÙ„ÙŠØ©")
            st.image(image, caption="Original", use_column_width=True)
        
        with col2:
            st.subheader("Ø§Ù†Ø¹ÙƒØ§Ø³")
            st.image(step1, caption="Flipped", use_column_width=True)
        
        with col3:
            st.subheader("Ø¯ÙˆØ±Ø§Ù†")
            st.image(step2, caption="Rotated", use_column_width=True)
        
        with col4:
            st.subheader("ØªØµØºÙŠØ±")
            st.image(step3, caption="Scaled", use_column_width=True)
    
    # Ø¹Ø±Ø¶ Ù…ØµÙÙˆÙØ© Ø§Ù„ØªØ­ÙˆÙŠÙ„
    if transform_type in ["Translation", "Rotation", "Affine Transform"]:
        st.markdown("### ğŸ”¢ Ù…ØµÙÙˆÙØ© Ø§Ù„ØªØ­ÙˆÙŠÙ„")
        
        if transform_type == "Translation":
            matrix_display = M
        elif transform_type == "Rotation":
            matrix_display = M
        elif transform_type == "Affine Transform":
            matrix_display = M
        
        st.write("**Ù…ØµÙÙˆÙØ© Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©:**")
        st.write(matrix_display)
        
        # Ø´Ø±Ø­ Ø§Ù„Ù…ØµÙÙˆÙØ©
        if transform_type == "Translation":
            st.write("""
            **Ø´Ø±Ø­ Ø§Ù„Ù…ØµÙÙˆÙØ©:**
            - Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø£ÙˆÙ„: Ù…Ø¹Ø§Ù…Ù„ X (1 = Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±)
            - Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø«Ø§Ù†ÙŠ: Ù…Ø¹Ø§Ù…Ù„ Y (1 = Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±)  
            - Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø«Ø§Ù„Ø«: Ø§Ù„Ø¥Ø²Ø§Ø­Ø© (tx, ty)
            """)
        elif transform_type == "Rotation":
            st.write("""
            **Ø´Ø±Ø­ Ø§Ù„Ù…ØµÙÙˆÙØ©:**
            - cos(Î¸), -sin(Î¸): Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø¯ÙˆØ±Ø§Ù†
            - sin(Î¸), cos(Î¸): Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø¯ÙˆØ±Ø§Ù†
            - Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø«Ø§Ù„Ø«: Ø§Ù„Ø¥Ø²Ø§Ø­Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ø¯ÙˆØ±Ø§Ù†
            """)

def show_lecture9():
    st.title("Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 9: Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ø®ØªØ§Ù…ÙŠ")
    
    # Ù…Ù‚Ø¯Ù…Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
    st.markdown("""
    <div class="theory-box">
    <h3>ğŸ¯ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ø®ØªØ§Ù…ÙŠ</h3>
    <p><strong>Ø§Ù„Ù‡Ø¯Ù:</strong> ØªØ·Ø¨ÙŠÙ‚ Ø´Ø§Ù…Ù„ Ù„Ø¬Ù…ÙŠØ¹ ØªÙ‚Ù†ÙŠØ§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„ØªÙŠ ØªØ¹Ù„Ù…Ù†Ø§Ù‡Ø§</p>
    <p>ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ØŒ Ø³ØªØªÙ…ÙƒÙ† Ù…Ù†:</p>
    <ul>
    <li>Ø±ÙØ¹ ØµÙˆØ±Ø© Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… ØµÙˆØ±Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ©</li>
    <li>Ø¨Ù†Ø§Ø¡ pipeline Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø®ØµØµ</li>
    <li>ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù…Ù„ÙŠØ§Øª Ù…ØªØªØ§Ù„ÙŠØ©</li>
    <li>Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ­ÙØ¸Ù‡Ø§</li>
    </ul>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
    st.markdown("## ğŸ“ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©", type=['png', 'jpg', 'jpeg'], key="final_project")
    
    with col2:
        sample_options = st.selectbox(
            "Ø£Ùˆ Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ©:",
            ["Ù„Ø§ Ø´ÙŠØ¡", "ØµÙˆØ±Ø© Ù…Ù„ÙˆÙ†Ø© Ø¨Ø³ÙŠØ·Ø©", "ØµÙˆØ±Ø© Ù…ÙØµÙ„Ø©", "ØµÙˆØ±Ø© Ø«Ù†Ø§Ø¦ÙŠØ©", "ØµÙˆØ±Ø© Ø¨Ø¶ÙˆØ¶Ø§Ø¡"]
        )
        
        if sample_options != "Ù„Ø§ Ø´ÙŠØ¡":
            if sample_options == "ØµÙˆØ±Ø© Ù…Ù„ÙˆÙ†Ø© Ø¨Ø³ÙŠØ·Ø©":
                image = create_sample_image()
            elif sample_options == "ØµÙˆØ±Ø© Ù…ÙØµÙ„Ø©":
                image = create_detailed_sample_image()
            elif sample_options == "ØµÙˆØ±Ø© Ø«Ù†Ø§Ø¦ÙŠØ©":
                image = create_binary_sample_image()
            elif sample_options == "ØµÙˆØ±Ø© Ø¨Ø¶ÙˆØ¶Ø§Ø¡":
                base_image = create_sample_image()
                image = add_noise_to_image(base_image, "Gaussian", 0.1)
        elif uploaded_file is not None:
            image = load_image(uploaded_file)
        else:
            image = None
    
    if image is not None:
        # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
        st.markdown("### ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©")
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.image(image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_column_width=True)
        
        with col2:
            st.write(f"**Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯:** {image.shape}")
            st.write(f"**Ø§Ù„Ù†ÙˆØ¹:** {'Ù…Ù„ÙˆÙ†Ø©' if len(image.shape) == 3 else 'Ø±Ù…Ø§Ø¯ÙŠØ©'}")
            st.write(f"**Ø§Ù„Ø­Ø¬Ù…:** {image.size:,} Ø¨ÙƒØ³Ù„")
            st.write(f"**Ù…ØªÙˆØ³Ø· Ø§Ù„Ù‚ÙŠÙ…:** {image.mean():.1f}")
        
        st.markdown("---")
        
        # Ø¨Ù†Ø§Ø¡ Pipeline Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        st.markdown("## âš™ï¸ Ø¨Ù†Ø§Ø¡ Pipeline Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©")
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª
        st.markdown("### 1ï¸âƒ£ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª")
        
        operations = []
        
        # Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø£ÙˆÙ„Ù‰
        op1 = st.selectbox("Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø£ÙˆÙ„Ù‰:", 
                          ["Ù„Ø§ Ø´ÙŠØ¡", "ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ÙŠ", "ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø³Ø·ÙˆØ¹/Ø§Ù„ØªØ¨Ø§ÙŠÙ†", "ØªØ·Ø¨ÙŠÙ‚ ÙÙ„ØªØ±", "ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù"])
        
        if op1 != "Ù„Ø§ Ø´ÙŠØ¡":
            operations.append(op1)
            
            if op1 == "ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø³Ø·ÙˆØ¹/Ø§Ù„ØªØ¨Ø§ÙŠÙ†":
                col1, col2 = st.columns(2)
                with col1:
                    brightness1 = st.slider("Ø§Ù„Ø³Ø·ÙˆØ¹", -100, 100, 0, key="bright1")
                with col2:
                    contrast1 = st.slider("Ø§Ù„ØªØ¨Ø§ÙŠÙ†", 0.1, 3.0, 1.0, 0.1, key="contrast1")
            
            elif op1 == "ØªØ·Ø¨ÙŠÙ‚ ÙÙ„ØªØ±":
                filter1 = st.selectbox("Ù†ÙˆØ¹ Ø§Ù„ÙÙ„ØªØ±:", ["Blur", "Gaussian Blur", "Sharpen"], key="filter1")
                if filter1 in ["Blur", "Gaussian Blur"]:
                    kernel_size1 = st.slider("Ø­Ø¬Ù… Ø§Ù„ÙÙ„ØªØ±", 3, 15, 5, step=2, key="kernel1")
            
            elif op1 == "ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù":
                edge_method1 = st.selectbox("Ø·Ø±ÙŠÙ‚Ø© ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù:", ["Canny", "Sobel", "Laplacian"], key="edge1")
                if edge_method1 == "Canny":
                    threshold1_1 = st.slider("Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ø³ÙÙ„Ù‰", 0, 255, 50, key="thresh1_1")
                    threshold2_1 = st.slider("Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ø¹Ù„ÙŠØ§", 0, 255, 150, key="thresh2_1")
        
        # Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø«Ø§Ù†ÙŠØ©
        if operations:
            op2 = st.selectbox("Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø«Ø§Ù†ÙŠØ©:", 
                              ["Ù„Ø§ Ø´ÙŠØ¡", "ØªØ·Ø¨ÙŠÙ‚ ÙÙ„ØªØ±", "Ø¹Ù…Ù„ÙŠØ§Øª Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©", "ØªØ­ÙˆÙŠÙ„ Ù‡Ù†Ø¯Ø³ÙŠ", "Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡"])
            
            if op2 != "Ù„Ø§ Ø´ÙŠØ¡":
                operations.append(op2)
                
                if op2 == "ØªØ·Ø¨ÙŠÙ‚ ÙÙ„ØªØ±":
                    filter2 = st.selectbox("Ù†ÙˆØ¹ Ø§Ù„ÙÙ„ØªØ±:", ["Median", "Bilateral", "Emboss"], key="filter2")
                    if filter2 == "Median":
                        kernel_size2 = st.slider("Ø­Ø¬Ù… Ø§Ù„ÙÙ„ØªØ±", 3, 15, 5, step=2, key="kernel2")
                
                elif op2 == "Ø¹Ù…Ù„ÙŠØ§Øª Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©":
                    morph_op2 = st.selectbox("Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©:", ["Opening", "Closing", "Erosion", "Dilation"], key="morph2")
                    morph_kernel_size2 = st.slider("Ø­Ø¬Ù… Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø¨Ù†Ø§Ø¦ÙŠ", 3, 15, 5, step=2, key="morph_kernel2")
                
                elif op2 == "ØªØ­ÙˆÙŠÙ„ Ù‡Ù†Ø¯Ø³ÙŠ":
                    transform2 = st.selectbox("Ù†ÙˆØ¹ Ø§Ù„ØªØ­ÙˆÙŠÙ„:", ["Rotation", "Scaling", "Flipping"], key="transform2")
                    if transform2 == "Rotation":
                        angle2 = st.slider("Ø²Ø§ÙˆÙŠØ© Ø§Ù„Ø¯ÙˆØ±Ø§Ù†", -180, 180, 0, key="angle2")
                    elif transform2 == "Scaling":
                        scale2 = st.slider("Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„ØªÙƒØ¨ÙŠØ±", 0.1, 2.0, 1.0, 0.1, key="scale2")
                    elif transform2 == "Flipping":
                        flip_dir2 = st.selectbox("Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø§Ù†Ø¹ÙƒØ§Ø³:", ["Ø£ÙÙ‚ÙŠ", "Ø±Ø£Ø³ÙŠ"], key="flip2")
        
        # Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø«Ø§Ù„Ø«Ø©
        if len(operations) >= 2:
            op3 = st.selectbox("Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø«Ø§Ù„Ø«Ø©:", 
                              ["Ù„Ø§ Ø´ÙŠØ¡", "ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø©", "ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ", "ØªØ·Ø¨ÙŠÙ‚ Ø¹ØªØ¨Ø©"])
            
            if op3 != "Ù„Ø§ Ø´ÙŠØ¡":
                operations.append(op3)
                
                if op3 == "ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±Ø©":
                    enhance_type = st.selectbox("Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ø³ÙŠÙ†:", ["Sharpen", "Contrast Enhancement"], key="enhance3")
                elif op3 == "ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ":
                    final_edge = st.selectbox("Ø·Ø±ÙŠÙ‚Ø© ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù:", ["Canny", "Sobel"], key="final_edge")
                elif op3 == "ØªØ·Ø¨ÙŠÙ‚ Ø¹ØªØ¨Ø©":
                    threshold_method = st.selectbox("Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¹ØªØ¨Ø©:", ["Manual", "Otsu"], key="thresh_method")
                    if threshold_method == "Manual":
                        threshold_val = st.slider("Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¹ØªØ¨Ø©", 0, 255, 127, key="thresh_val")
        
        # ØªØ·Ø¨ÙŠÙ‚ Pipeline
        if st.button("ğŸš€ ØªØ·Ø¨ÙŠÙ‚ Pipeline", type="primary"):
            st.markdown("### ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©")
            
            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª ØªØ¯Ø±ÙŠØ¬ÙŠØ§Ù‹
            current_image = image.copy()
            results = [("Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", current_image)]
            
            for i, operation in enumerate(operations):
                if operation == "ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ÙŠ":
                    if len(current_image.shape) == 3:
                        current_image = cv2.cvtColor(current_image, cv2.COLOR_RGB2GRAY)
                    results.append(("Ø±Ù…Ø§Ø¯ÙŠ", current_image))
                
                elif operation == "ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø³Ø·ÙˆØ¹/Ø§Ù„ØªØ¨Ø§ÙŠÙ†":
                    processed = current_image.copy().astype(np.float32)
                    processed = contrast1 * processed + brightness1
                    current_image = np.clip(processed, 0, 255).astype(np.uint8)
                    results.append((f"Ø³Ø·ÙˆØ¹/ØªØ¨Ø§ÙŠÙ†", current_image))
                
                elif operation == "ØªØ·Ø¨ÙŠÙ‚ ÙÙ„ØªØ±":
                    if i == 0:  # Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø£ÙˆÙ„Ù‰
                        if filter1 == "Blur":
                            current_image = cv2.blur(current_image, (kernel_size1, kernel_size1))
                        elif filter1 == "Gaussian Blur":
                            current_image = cv2.GaussianBlur(current_image, (kernel_size1, kernel_size1), 0)
                        elif filter1 == "Sharpen":
                            kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
                            current_image = cv2.filter2D(current_image, -1, kernel)
                        results.append((f"ÙÙ„ØªØ± {filter1}", current_image))
                    else:  # Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø«Ø§Ù†ÙŠØ©
                        if filter2 == "Median":
                            current_image = cv2.medianBlur(current_image, kernel_size2)
                        elif filter2 == "Bilateral":
                            current_image = cv2.bilateralFilter(current_image, 9, 75, 75)
                        elif filter2 == "Emboss":
                            kernel = np.array([[-2, -1, 0], [-1, 1, 1], [0, 1, 2]])
                            current_image = cv2.filter2D(current_image, -1, kernel)
                        results.append((f"ÙÙ„ØªØ± {filter2}", current_image))
                
                elif operation == "ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù":
                    if len(current_image.shape) == 3:
                        gray = cv2.cvtColor(current_image, cv2.COLOR_RGB2GRAY)
                    else:
                        gray = current_image
                    
                    if edge_method1 == "Canny":
                        current_image = cv2.Canny(gray, threshold1_1, threshold2_1)
                    elif edge_method1 == "Sobel":
                        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
                        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
                        current_image = np.uint8(np.sqrt(sobelx**2 + sobely**2))
                    elif edge_method1 == "Laplacian":
                        current_image = np.uint8(np.absolute(cv2.Laplacian(gray, cv2.CV_64F)))
                    
                    results.append((f"Ø­ÙˆØ§Ù {edge_method1}", current_image))
                
                elif operation == "Ø¹Ù…Ù„ÙŠØ§Øª Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©":
                    if len(current_image.shape) == 3:
                        gray = cv2.cvtColor(current_image, cv2.COLOR_RGB2GRAY)
                    else:
                        gray = current_image
                    
                    _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)
                    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (morph_kernel_size2, morph_kernel_size2))
                    
                    if morph_op2 == "Opening":
                        current_image = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
                    elif morph_op2 == "Closing":
                        current_image = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
                    elif morph_op2 == "Erosion":
                        current_image = cv2.erode(binary, kernel)
                    elif morph_op2 == "Dilation":
                        current_image = cv2.dilate(binary, kernel)
                    
                    results.append((f"Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠ {morph_op2}", current_image))
                
                elif operation == "ØªØ­ÙˆÙŠÙ„ Ù‡Ù†Ø¯Ø³ÙŠ":
                    height, width = current_image.shape[:2]
                    
                    if transform2 == "Rotation":
                        M = cv2.getRotationMatrix2D((width//2, height//2), angle2, 1)
                        current_image = cv2.warpAffine(current_image, M, (width, height))
                    elif transform2 == "Scaling":
                        new_width = int(width * scale2)
                        new_height = int(height * scale2)
                        current_image = cv2.resize(current_image, (new_width, new_height))
                    elif transform2 == "Flipping":
                        if flip_dir2 == "Ø£ÙÙ‚ÙŠ":
                            current_image = cv2.flip(current_image, 1)
                        elif flip_dir2 == "Ø±Ø£Ø³ÙŠ":
                            current_image = cv2.flip(current_image, 0)
                    
                    results.append((f"ØªØ­ÙˆÙŠÙ„ {transform2}", current_image))
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            cols_per_row = 3
            for i in range(0, len(results), cols_per_row):
                cols = st.columns(cols_per_row)
                for j in range(cols_per_row):
                    if i + j < len(results):
                        with cols[j]:
                            name, img = results[i + j]
                            st.subheader(name)
                            st.image(img, caption=name, use_column_width=True, clamp=True)
                            if hasattr(img, 'shape'):
                                st.write(f"Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯: {img.shape}")
            
            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
            st.markdown("### ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©")
            
            final_image = results[-1][1]
            
            stats_col1, stats_col2, stats_col3 = st.columns(3)
            
            with stats_col1:
                st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø·Ø¨Ù‚Ø©", len(operations))
                st.metric("Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ø£ØµÙ„ÙŠØ©", f"{image.shape[0]}Ã—{image.shape[1]}")
            
            with stats_col2:
                st.metric("Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©", f"{final_image.shape[0]}Ã—{final_image.shape[1]}")
                original_size = image.shape[0] * image.shape[1]
                final_size = final_image.shape[0] * final_image.shape[1]
                size_change = ((final_size - original_size) / original_size) * 100
                st.metric("ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù…", f"{size_change:+.1f}%")
            
            with stats_col3:
                st.metric("Ù…ØªÙˆØ³Ø· Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø£ØµÙ„ÙŠØ©", f"{image.mean():.1f}")
                st.metric("Ù…ØªÙˆØ³Ø· Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©", f"{final_image.mean():.1f}")
            
            # Ø®ÙŠØ§Ø± Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø©
            st.markdown("### ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø©")
            
            if st.button("Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©"):
                # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ PIL Ù„Ù„Ø­ÙØ¸
                if len(final_image.shape) == 3:
                    pil_image = Image.fromarray(final_image)
                else:
                    pil_image = Image.fromarray(final_image)
                
                # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø©
                output_path = "/home/ubuntu/image_processing_app/processed_image.png"
                pil_image.save(output_path)
                
                st.success(f"ØªÙ… Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© ÙÙŠ: {output_path}")
                
                # Ø¹Ø±Ø¶ Ø±Ø§Ø¨Ø· Ø§Ù„ØªØ­Ù…ÙŠÙ„
                with open(output_path, "rb") as file:
                    st.download_button(
                        label="ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©",
                        data=file.read(),
                        file_name="processed_image.png",
                        mime="image/png"
                    )
    
    else:
        st.info("ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© Ø£Ùˆ Ø§Ø®ØªÙŠØ§Ø± ØµÙˆØ±Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ© Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹.")
    
    # Ø®Ù„Ø§ØµØ© Ø§Ù„Ø³Ù„Ø³Ù„Ø©
    st.markdown("---")
    st.markdown("""
    ## ğŸ“ Ø®Ù„Ø§ØµØ© Ø§Ù„Ø³Ù„Ø³Ù„Ø©
    
    ØªÙ‡Ø§Ù†ÙŠÙ†Ø§! Ù„Ù‚Ø¯ Ø£ÙƒÙ…Ù„Øª Ø³Ù„Ø³Ù„Ø© Ù…Ø­Ø§Ø¶Ø±Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©. 
    
    **Ù…Ø§ ØªØ¹Ù„Ù…ØªÙ‡:**
    - Ø£Ø³Ø§Ø³ÙŠØ§Øª Ø§Ù„ØµÙˆØ± Ø§Ù„Ø±Ù‚Ù…ÙŠØ© ÙˆÙ…Ø¹Ù…Ø§Ø±ÙŠØ© Ø§Ù„Ø¨ÙƒØ³Ù„
    - Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù† ÙˆØªØ­ÙˆÙŠÙ„Ø§ØªÙ‡Ø§
    - Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù†Ù‚Ø·ÙŠØ© ÙˆØ§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ†
    - Ø§Ù„ÙÙ„Ø§ØªØ± ÙˆØ§Ù„Ø§Ù„ØªÙØ§Ù Ù„ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±
    - ØªÙ‚Ù†ÙŠØ§Øª Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
    - Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù
    - Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø´ÙƒØ§Ù„
    - Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ©
    - Ø¨Ù†Ø§Ø¡ pipeline Ù…Ø¹Ø§Ù„Ø¬Ø© Ø´Ø§Ù…Ù„
    
    **Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:**
    - Ø¬Ø±Ø¨ ØªØ·Ø¨ÙŠÙ‚ Ù‡Ø°Ù‡ Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø¹Ù„Ù‰ ØµÙˆØ±Ùƒ Ø§Ù„Ø®Ø§ØµØ©
    - Ø§ÙƒØªØ´Ù ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø£Ø®Ø±Ù‰ ÙÙŠ Ø§Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ø­Ø§Ø³ÙˆØ¨ÙŠØ©
    - ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø²ÙŠØ¯ Ø¹Ù† Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±
    """)
    
    st.balloons()  # Ø§Ø­ØªÙØ§Ù„ Ø¨Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ø³Ù„Ø³Ù„Ø©!

# Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±
def load_image(image_file):
    """ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø±ÙÙˆØ¹"""
    img = Image.open(image_file)
    return np.array(img)

def convert_to_opencv(pil_image):
    """ØªØ­ÙˆÙŠÙ„ ØµÙˆØ±Ø© PIL Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ OpenCV"""
    return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)

def convert_to_pil(opencv_image):
    """ØªØ­ÙˆÙŠÙ„ ØµÙˆØ±Ø© OpenCV Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ PIL"""
    return Image.fromarray(cv2.cvtColor(opencv_image, cv2.COLOR_BGR2RGB))

if __name__ == "__main__":
    main()

